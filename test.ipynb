{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import importlib\n",
    "import Semantic_Meaningfulness_v2\n",
    "from Semantic_Meaningfulness_v2 import Sematic\n",
    "importlib.reload(Semantic_Meaningfulness_v2)\n",
    "import carla.recourse_methods.catalog as recourse_catalog\n",
    "from carla.data.causal_model import CausalModel\n",
    "from carla.models.catalog import MLModelCatalog\n",
    "from carla.models.negative_instances import predict_negative_instances\n",
    "from carla.data.catalog import CsvCatalog\n",
    "from carla.evaluation.catalog.success_rate import SuccessRate\n",
    "#from carla.recourse_methods.catalog import recourse_catalog\n",
    "#from carla.recourse_methods.catalog.roar.model import Roar\n",
    "from carla.recourse_methods.catalog.causal_recourse import (\n",
    "    CausalRecourse,\n",
    "    constraints,\n",
    "    samplers,\n",
    ")\n",
    "#from carla.data.causal_model.synthethic_data import SCMDataset\n",
    "from carla.recourse_methods import GrowingSpheres\n",
    "from causal_recourse_do_calculus.model import CausalRecourse_DoCalculus\n",
    "from carla import Benchmark\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import os \n",
    "import pickle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Distribution Finished\n",
      "balance on test set 0.4368, balance on test set 0.4272\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.3632 Acc: 0.8531\n",
      "\n",
      "test Loss: 0.1929 Acc: 0.9332\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.1340 Acc: 0.9627\n",
      "\n",
      "test Loss: 0.0916 Acc: 0.9860\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0788 Acc: 0.9808\n",
      "\n",
      "test Loss: 0.0610 Acc: 0.9908\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0599 Acc: 0.9828\n",
      "\n",
      "test Loss: 0.0523 Acc: 0.9844\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0497 Acc: 0.9840\n",
      "\n",
      "test Loss: 0.0402 Acc: 0.9920\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0436 Acc: 0.9855\n",
      "\n",
      "test Loss: 0.0425 Acc: 0.9812\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0402 Acc: 0.9871\n",
      "\n",
      "test Loss: 0.0309 Acc: 0.9932\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0362 Acc: 0.9877\n",
      "\n",
      "test Loss: 0.0328 Acc: 0.9884\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0361 Acc: 0.9864\n",
      "\n",
      "test Loss: 0.0466 Acc: 0.9768\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0326 Acc: 0.9877\n",
      "\n",
      "test Loss: 0.0621 Acc: 0.9644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def MLP(dataset, name,hyperparams,i):\n",
    "    '''\n",
    "    Load and return MLP. \n",
    "    Attributes: \n",
    "        dataset carla.XXX : data to train on \n",
    "        name str: dataset name \n",
    "    Returns: \n",
    "        carla.XXX\n",
    "    '''\n",
    "    \n",
    "    training_params =hyperparams #{\"lr\": 0.01, \"epochs\": 10, \"batch_size\": 16, \"hidden_size\": [18, 9, 3]}\n",
    "    #if name=='economic':\n",
    "    #     training_params = {\"lr\": 0.002, \"epochs\": 10, \"batch_size\": 1024, \"hidden_size\": [18, 9, 3],' num_of_classes':2}\n",
    "   \n",
    "\n",
    "    ml_model = MLModelCatalog(\n",
    "    dataset, model_type=\"ann\", load_online=False, backend=\"pytorch\"\n",
    "    )\n",
    "\n",
    "    ml_model.train(\n",
    "        learning_rate=training_params[\"lr\"],\n",
    "        epochs=training_params[\"epochs\"],\n",
    "        batch_size=training_params[\"batch_size\"],\n",
    "        hidden_size=training_params[\"hidden_size\"],\n",
    "        force_train=True\n",
    "        )\n",
    "\n",
    "    return ml_model\n",
    "\n",
    "def data(name, not_causal=True, scaler='Identity'):\n",
    "    '''\n",
    "    Load and return Toy Dataset.\n",
    "    Attribute: \n",
    "        name str: Name of the Dataset. \n",
    "\n",
    "    Returns: \n",
    "        (dataset, scm, scm_output): returns Dataset, Structural Causal Model and Structural Causal Model with output Layer.\n",
    "    '''\n",
    "    scm = CausalModel(f\"{name}\")\n",
    "    scm_output = CausalModel(f\"{name}-output\")\n",
    "    if not os.path.isdir(f'./data/{name}'):\n",
    "        os.mkdir(f'./data/{name}')\n",
    "    if not os.path.isfile(f'./data/{name}/{name}.csv'):\n",
    "        print('TRUE 1 ')\n",
    "        # generate data\n",
    "        dataset = scm.generate_dataset(10000, False)\n",
    "        print(f'./data/{name}/{name}.csv')\n",
    "        dataset.df.to_csv(f'./data/{name}/{name}.csv', index=False)\n",
    "        #pickle.dump(dataset.train_raw, open(f'./data/{name}/{name}_train_raw.pkl','wb'))\n",
    "        #pickle.dump(dataset.test_raw, open(f'./data/{name}/{name}_test_raw.pkl','wb'))\n",
    "        #pickle.dump(dataset.raw, open(f'./data/{name}/{name}_raw.pkl','wb'))\n",
    "        #pickle.dump(dataset.noise, open(f'./data/{name}/{name}_noise.pkl','wb'))\n",
    "        if not_causal:\n",
    "            dataset = pd.read_csv(f'./data/{name}/{name}.csv')\n",
    "            #TODO Better way for defining continous varaibles ?\n",
    "            continuous_wachter = dataset.drop(columns=['label']).columns\n",
    "            dataset = CsvCatalog(file_path=f'./data/{name}/{name}.csv',\n",
    "                     continuous=continuous_wachter,\n",
    "                     categorical=[],\n",
    "                     immutables=[],\n",
    "                     target='label',\n",
    "                     scaling_method=scaler)\n",
    "    else: \n",
    "        if not_causal:\n",
    "            dataset = pd.read_csv(f'./data/{name}/{name}.csv')\n",
    "            #TODO Better way for defining continous varaibles ?\n",
    "            continuous_wachter = dataset.drop(columns=['label']).columns\n",
    "            dataset = CsvCatalog(file_path=f'./data/{name}/{name}.csv',\n",
    "                     continuous=continuous_wachter,\n",
    "                     categorical=[],\n",
    "                     immutables=[],\n",
    "                     target='label',\n",
    "                     scaling_method=scaler)\n",
    "        else: \n",
    "\n",
    "            dataset = pd.read_csv(f'./data/{name}/{name}.csv')\n",
    "            continuous_wachter = dataset.drop(columns=['label']).columns\n",
    "            #TODO Does Scaling Method Idendity make sense ? \n",
    "            dataset = CsvCatalog(file_path=f'./data/{name}/{name}.csv',\n",
    "                     continuous=continuous_wachter,\n",
    "                     categorical=[],\n",
    "                     immutables=[],\n",
    "                     target='label',\n",
    "                     scaling_method=scaler)\n",
    "    \n",
    "    return dataset, scm , scm_output\n",
    "\n",
    "\n",
    "hyperparams={\n",
    "        #0: {\"lr\": 0.1, \"epochs\": 10, \"batch_size\": 16, \"hidden_size\": [18, 9, 3]},\n",
    "        #1: {\"lr\": 0.01, \"epochs\": 10, \"batch_size\": 16, \"hidden_size\": [18, 9, 3]},\n",
    "        0: {\"lr\": 0.001, \"epochs\": 10, \"batch_size\": 16, \"hidden_size\": [18, 9, 3]}\n",
    "\n",
    "\n",
    "    }\n",
    "    #import 1_Experiment\n",
    "    #SEED Setting\n",
    "\n",
    "\n",
    "scaler='MinMax'\n",
    "    #Load Dataset    \n",
    "dataset, scm, scm_output=data('economic', True,scaler)\n",
    "\n",
    "ml_model= MLP(dataset, 'economic',hyperparams[0],0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CARLA-7s4zdYsf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05951db0b7a8fb6113eda4ec48ea77d75ed33c5045908c39c7a5079655347ffc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
