{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n"
     ]
    }
   ],
   "source": [
    "from carla import Benchmark\n",
    "import carla.evaluation.catalog as evaluation_catalog\n",
    "from carla.data.catalog import OnlineCatalog\n",
    "from carla.models.catalog import MLModelCatalog\n",
    "from carla.models.negative_instances import predict_negative_instances\n",
    "import carla.recourse_methods.catalog as recourse_catalog\n",
    "import shap \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from carla.data.causal_model import CausalModel\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from carla.data.catalog import CsvCatalog\n",
    "import numpy as np \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load Data \n",
    "dataframe = pd.read_csv('./census.csv', index_col=['Unnamed: 0'])\n",
    "continuous = dataframe.drop(columns=['target']).columns\n",
    "\n",
    "dataset = CsvCatalog(file_path=\"census.csv\",\n",
    "                     continuous=continuous,\n",
    "                     categorical=[],\n",
    "                     immutables=[],\n",
    "                     target='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance on test set 0.24156429156429157, balance on test set 0.2385456332145928\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.4017 Acc: 0.8102\n",
      "\n",
      "test Loss: 0.4050 Acc: 0.8124\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.3556 Acc: 0.8320\n",
      "\n",
      "test Loss: 0.5835 Acc: 0.6692\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.3484 Acc: 0.8358\n",
      "\n",
      "test Loss: 0.3911 Acc: 0.8262\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.3455 Acc: 0.8382\n",
      "\n",
      "test Loss: 0.3383 Acc: 0.8419\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.3420 Acc: 0.8404\n",
      "\n",
      "test Loss: 0.3798 Acc: 0.8241\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.3415 Acc: 0.8397\n",
      "\n",
      "test Loss: 0.3337 Acc: 0.8461\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3393 Acc: 0.8410\n",
      "\n",
      "test Loss: 0.3402 Acc: 0.8360\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.3393 Acc: 0.8407\n",
      "\n",
      "test Loss: 0.3297 Acc: 0.8473\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.3376 Acc: 0.8401\n",
      "\n",
      "test Loss: 0.3445 Acc: 0.8477\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.3362 Acc: 0.8408\n",
      "\n",
      "test Loss: 0.3331 Acc: 0.8449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model \n",
    "\n",
    "training_params = {\"lr\": 0.01, \"epochs\": 10, \"batch_size\": 16, \"hidden_size\": [18, 9, 2]}\n",
    "\n",
    "ml_model = MLModelCatalog(\n",
    "    dataset, model_type=\"ann\", load_online=False, backend=\"pytorch\"\n",
    ")\n",
    "ml_model.train(\n",
    "    learning_rate=training_params[\"lr\"],\n",
    "    epochs=training_params[\"epochs\"],\n",
    "    batch_size=training_params[\"batch_size\"],\n",
    "    hidden_size=training_params[\"hidden_size\"],\n",
    "    force_train=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>Education-Num</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>...</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per week</th>\n",
       "      <th>Country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.479452</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.205479</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.205479</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.356164</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.246575</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.575342</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0       Age  Workclass  Education-Num  Marital Status  ...  \\\n",
       "0            0  0.301370      0.875       0.800000        0.666667  ...   \n",
       "1            1  0.452055      0.750       0.800000        0.333333  ...   \n",
       "2            2  0.287671      0.500       0.533333        0.000000  ...   \n",
       "3            3  0.493151      0.500       0.400000        0.333333  ...   \n",
       "6            6  0.438356      0.500       0.266667        0.500000  ...   \n",
       "7            7  0.479452      0.750       0.533333        0.333333  ...   \n",
       "11          11  0.178082      0.875       0.800000        0.333333  ...   \n",
       "12          12  0.082192      0.500       0.800000        0.666667  ...   \n",
       "13          13  0.205479      0.500       0.733333        0.666667  ...   \n",
       "14          14  0.315068      0.500       0.666667        0.333333  ...   \n",
       "15          15  0.232877      0.500       0.200000        0.333333  ...   \n",
       "16          16  0.109589      0.750       0.533333        0.666667  ...   \n",
       "17          17  0.205479      0.500       0.533333        0.666667  ...   \n",
       "18          18  0.287671      0.500       0.400000        0.333333  ...   \n",
       "19          19  0.356164      0.750       0.866667        0.000000  ...   \n",
       "21          21  0.506849      0.500       0.533333        0.833333  ...   \n",
       "22          22  0.246575      0.125       0.266667        0.333333  ...   \n",
       "24          24  0.575342      0.500       0.533333        0.000000  ...   \n",
       "26          26  0.027397      0.500       0.533333        0.666667  ...   \n",
       "28          28  0.301370      0.500       0.533333        0.000000  ...   \n",
       "\n",
       "    Capital Gain  Capital Loss  Hours per week   Country  target  \n",
       "0        0.02174           0.0        0.397959  0.951220   False  \n",
       "1        0.00000           0.0        0.122449  0.951220   False  \n",
       "2        0.00000           0.0        0.397959  0.951220   False  \n",
       "3        0.00000           0.0        0.397959  0.951220   False  \n",
       "6        0.00000           0.0        0.153061  0.560976   False  \n",
       "7        0.00000           0.0        0.448980  0.951220    True  \n",
       "11       0.00000           0.0        0.397959  0.463415    True  \n",
       "12       0.00000           0.0        0.295918  0.951220   False  \n",
       "13       0.00000           0.0        0.500000  0.951220   False  \n",
       "14       0.00000           0.0        0.397959  0.000000    True  \n",
       "15       0.00000           0.0        0.448980  0.634146   False  \n",
       "16       0.00000           0.0        0.346939  0.951220   False  \n",
       "17       0.00000           0.0        0.397959  0.951220   False  \n",
       "18       0.00000           0.0        0.500000  0.951220   False  \n",
       "19       0.00000           0.0        0.448980  0.951220    True  \n",
       "21       0.00000           0.0        0.193878  0.951220   False  \n",
       "22       0.00000           0.0        0.397959  0.951220   False  \n",
       "24       0.00000           0.0        0.397959  0.951220   False  \n",
       "26       0.00000           0.0        0.397959  0.951220   False  \n",
       "28       0.00000           0.0        0.806122  0.951220   False  \n",
       "\n",
       "[20 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from carla.models.negative_instances import predict_negative_instances\n",
    "import carla.recourse_methods.catalog as recourse_catalog\n",
    "\n",
    "factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "test_factual = factuals.iloc[:20]\n",
    "\n",
    "display(test_factual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Country</th>\n",
       "      <th>Education-Num</th>\n",
       "      <th>...</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Race</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Workclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.311370</td>\n",
       "      <td>0.031740</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.961219</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081429</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.865000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.432132</td>\n",
       "      <td>0.019929</td>\n",
       "      <td>0.019924</td>\n",
       "      <td>0.931479</td>\n",
       "      <td>0.819926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305586</td>\n",
       "      <td>1.019620</td>\n",
       "      <td>-0.019165</td>\n",
       "      <td>0.980100</td>\n",
       "      <td>0.733346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.327290</td>\n",
       "      <td>0.039664</td>\n",
       "      <td>0.039648</td>\n",
       "      <td>0.911597</td>\n",
       "      <td>0.572994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418259</td>\n",
       "      <td>0.960370</td>\n",
       "      <td>0.160387</td>\n",
       "      <td>1.039645</td>\n",
       "      <td>0.460424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.497894</td>\n",
       "      <td>0.039017</td>\n",
       "      <td>0.038691</td>\n",
       "      <td>0.913048</td>\n",
       "      <td>0.438506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467968</td>\n",
       "      <td>0.528517</td>\n",
       "      <td>-0.027334</td>\n",
       "      <td>0.966417</td>\n",
       "      <td>0.473702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.497616</td>\n",
       "      <td>0.097125</td>\n",
       "      <td>0.096461</td>\n",
       "      <td>0.463758</td>\n",
       "      <td>0.362831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669305</td>\n",
       "      <td>0.591714</td>\n",
       "      <td>0.299493</td>\n",
       "      <td>0.099424</td>\n",
       "      <td>0.508568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.459537</td>\n",
       "      <td>0.019921</td>\n",
       "      <td>0.019916</td>\n",
       "      <td>0.931508</td>\n",
       "      <td>0.553252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305572</td>\n",
       "      <td>1.019577</td>\n",
       "      <td>-0.019065</td>\n",
       "      <td>0.980110</td>\n",
       "      <td>0.733724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.188082</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.473415</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.724286</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.865000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.122006</td>\n",
       "      <td>0.039815</td>\n",
       "      <td>0.039811</td>\n",
       "      <td>0.982999</td>\n",
       "      <td>0.839814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111208</td>\n",
       "      <td>1.039798</td>\n",
       "      <td>0.639801</td>\n",
       "      <td>0.039802</td>\n",
       "      <td>0.539712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.235261</td>\n",
       "      <td>0.029457</td>\n",
       "      <td>0.029653</td>\n",
       "      <td>0.979778</td>\n",
       "      <td>0.762830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885413</td>\n",
       "      <td>0.529824</td>\n",
       "      <td>0.170163</td>\n",
       "      <td>0.970543</td>\n",
       "      <td>0.471448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.325068</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0.676667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224286</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.295062</td>\n",
       "      <td>0.066395</td>\n",
       "      <td>0.068930</td>\n",
       "      <td>0.676347</td>\n",
       "      <td>0.267254</td>\n",
       "      <td>...</td>\n",
       "      <td>1.031165</td>\n",
       "      <td>0.068614</td>\n",
       "      <td>-0.069826</td>\n",
       "      <td>0.934377</td>\n",
       "      <td>0.433771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.177561</td>\n",
       "      <td>0.069374</td>\n",
       "      <td>0.069606</td>\n",
       "      <td>1.019042</td>\n",
       "      <td>0.602667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425733</td>\n",
       "      <td>1.069409</td>\n",
       "      <td>0.531256</td>\n",
       "      <td>0.931338</td>\n",
       "      <td>0.683043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.264755</td>\n",
       "      <td>0.059281</td>\n",
       "      <td>0.059270</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>0.592609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559200</td>\n",
       "      <td>1.059123</td>\n",
       "      <td>0.740796</td>\n",
       "      <td>0.940739</td>\n",
       "      <td>0.441040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.307681</td>\n",
       "      <td>0.019638</td>\n",
       "      <td>0.019888</td>\n",
       "      <td>0.944496</td>\n",
       "      <td>0.419710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870352</td>\n",
       "      <td>1.019988</td>\n",
       "      <td>-0.020012</td>\n",
       "      <td>0.980385</td>\n",
       "      <td>0.480298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.385975</td>\n",
       "      <td>0.029841</td>\n",
       "      <td>0.029830</td>\n",
       "      <td>0.921406</td>\n",
       "      <td>0.896505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273794</td>\n",
       "      <td>0.970181</td>\n",
       "      <td>0.770193</td>\n",
       "      <td>0.029828</td>\n",
       "      <td>0.720217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.572565</td>\n",
       "      <td>0.087472</td>\n",
       "      <td>0.086913</td>\n",
       "      <td>0.863654</td>\n",
       "      <td>0.620003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659584</td>\n",
       "      <td>0.583367</td>\n",
       "      <td>0.889968</td>\n",
       "      <td>0.089943</td>\n",
       "      <td>0.475301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.293658</td>\n",
       "      <td>0.048987</td>\n",
       "      <td>0.049333</td>\n",
       "      <td>0.984823</td>\n",
       "      <td>0.315769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404768</td>\n",
       "      <td>0.549530</td>\n",
       "      <td>-0.049406</td>\n",
       "      <td>0.951222</td>\n",
       "      <td>0.075960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.644168</td>\n",
       "      <td>0.068913</td>\n",
       "      <td>0.068882</td>\n",
       "      <td>0.882386</td>\n",
       "      <td>0.602239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>0.931152</td>\n",
       "      <td>0.731185</td>\n",
       "      <td>0.068876</td>\n",
       "      <td>0.431255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.106418</td>\n",
       "      <td>0.079517</td>\n",
       "      <td>0.079486</td>\n",
       "      <td>1.028098</td>\n",
       "      <td>0.612824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292777</td>\n",
       "      <td>1.077381</td>\n",
       "      <td>0.520780</td>\n",
       "      <td>0.921113</td>\n",
       "      <td>0.426073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.321258</td>\n",
       "      <td>0.019909</td>\n",
       "      <td>0.019901</td>\n",
       "      <td>0.931330</td>\n",
       "      <td>0.553240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274908</td>\n",
       "      <td>0.980107</td>\n",
       "      <td>0.180115</td>\n",
       "      <td>1.019900</td>\n",
       "      <td>0.480132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age  Capital Gain  Capital Loss   Country  Education-Num  ...  \\\n",
       "0   0.311370      0.031740      0.010000  0.961219       0.810000  ...   \n",
       "1   0.432132      0.019929      0.019924  0.931479       0.819926  ...   \n",
       "2   0.327290      0.039664      0.039648  0.911597       0.572994  ...   \n",
       "3   0.497894      0.039017      0.038691  0.913048       0.438506  ...   \n",
       "6   0.497616      0.097125      0.096461  0.463758       0.362831  ...   \n",
       "7   0.459537      0.019921      0.019916  0.931508       0.553252  ...   \n",
       "11  0.188082      0.010000      0.010000  0.473415       0.810000  ...   \n",
       "12  0.122006      0.039815      0.039811  0.982999       0.839814  ...   \n",
       "13  0.235261      0.029457      0.029653  0.979778       0.762830  ...   \n",
       "14  0.325068      0.010000      0.010000 -0.010000       0.676667  ...   \n",
       "15  0.295062      0.066395      0.068930  0.676347       0.267254  ...   \n",
       "16  0.177561      0.069374      0.069606  1.019042       0.602667  ...   \n",
       "17  0.264755      0.059281      0.059270  1.010000       0.592609  ...   \n",
       "18  0.307681      0.019638      0.019888  0.944496       0.419710  ...   \n",
       "19  0.385975      0.029841      0.029830  0.921406       0.896505  ...   \n",
       "21  0.572565      0.087472      0.086913  0.863654       0.620003  ...   \n",
       "22  0.293658      0.048987      0.049333  0.984823       0.315769  ...   \n",
       "24  0.644168      0.068913      0.068882  0.882386       0.602239  ...   \n",
       "26  0.106418      0.079517      0.079486  1.028098       0.612824  ...   \n",
       "28  0.321258      0.019909      0.019901  0.931330       0.553240  ...   \n",
       "\n",
       "    Occupation      Race  Relationship       Sex  Workclass  \n",
       "0     0.081429  1.010000      0.190000  0.990000   0.865000  \n",
       "1     0.305586  1.019620     -0.019165  0.980100   0.733346  \n",
       "2     0.418259  0.960370      0.160387  1.039645   0.460424  \n",
       "3     0.467968  0.528517     -0.027334  0.966417   0.473702  \n",
       "6     0.669305  0.591714      0.299493  0.099424   0.508568  \n",
       "7     0.305572  1.019577     -0.019065  0.980110   0.733724  \n",
       "11    0.724286  0.260000     -0.010000  0.990000   0.865000  \n",
       "12    0.111208  1.039798      0.639801  0.039802   0.539712  \n",
       "13    0.885413  0.529824      0.170163  0.970543   0.471448  \n",
       "14    0.224286  0.260000     -0.010000  0.990000   0.490000  \n",
       "15    1.031165  0.068614     -0.069826  0.934377   0.433771  \n",
       "16    0.425733  1.069409      0.531256  0.931338   0.683043  \n",
       "17    0.559200  1.059123      0.740796  0.940739   0.441040  \n",
       "18    0.870352  1.019988     -0.020012  0.980385   0.480298  \n",
       "19    0.273794  0.970181      0.770193  0.029828   0.720217  \n",
       "21    0.659584  0.583367      0.889968  0.089943   0.475301  \n",
       "22    0.404768  0.549530     -0.049406  0.951222   0.075960  \n",
       "24    0.926401  0.931152      0.731185  0.068876   0.431255  \n",
       "26    0.292777  1.077381      0.520780  0.921113   0.426073  \n",
       "28    0.274908  0.980107      0.180115  1.019900   0.480132  \n",
       "\n",
       "[20 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyperparams = {\"loss_type\": \"BCE\", \"binary_cat_features\": True}\n",
    "\n",
    "recourse_method = recourse_catalog.Wachter(ml_model, hyperparams)\n",
    "df_cfs = recourse_method.get_counterfactuals(test_factual)\n",
    "\n",
    "display(df_cfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Histogram Features / true Positive / false Positive'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from carla.evaluation import remove_nans\n",
    "from carla.evaluation.api import Evaluation\n",
    "class Sematic(Evaluation):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mlmodel, causal_graph):\n",
    "        super().__init__()\n",
    "        self.mlmodel= ml_model\n",
    "        self.causal_graph=causal_graph\n",
    "    def evaluate(self,factual: np.ndarray, counterfactual: np.ndarray, causal_model):\n",
    "        # generate data \n",
    "        cf_label=self.ml_model.predict(counterfactual)\n",
    "        causal_label = None\n",
    "        if cf_label ==causal_label:\n",
    "            return 1 \n",
    "        else: \n",
    "            return 0\n",
    "\n",
    "''' \n",
    "Analysis\n",
    "Probitlity Distributions \n",
    "Histogram True Positive, False Positives \n",
    "'''\n",
    "'''\n",
    "Parts of counterfactuals actually change \n",
    "1hop and 2 hop relations \n",
    "'''\n",
    "'''Histogram Features / true Positive / false Positive'''\n",
    "# first initialize the benchmarking class by passing\n",
    "# black-box-model, recourse method, and factuals into it\n",
    "#benchmark = Benchmark(ml_model, recourse_method, factuals)\n",
    "\n",
    "# now you can decide if you want to run all measurements\n",
    "# or just specific ones.\n",
    "#evaluation_measures = [\n",
    "#    evaluation_catalog.YNN(benchmark.mlmodel, {\"y\": 5, \"cf_label\": 1}),\n",
    "#    evaluation_catalog.Distance(benchmark.mlmodel),\n",
    "#    evaluation_catalog.SuccessRate(),\n",
    "#    evaluation_catalog.Redundancy(benchmark.mlmodel, {\"cf_label\": 1}),\n",
    "#    evaluation_catalog.ConstraintViolation(benchmark.mlmodel),\n",
    "#    evaluation_catalog.AvgTime({\"time\": benchmark.timer}),\n",
    "#]\n",
    "\n",
    "# now run all implemented measurements and create a\n",
    "# DataFrame which consists of all results\n",
    "#results = benchmark.run_benchmark(evaluation_measures)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('CARLA-koH0yuP4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f55703f6f29bf5b3ae6360c8e9dbcc23e2b3226583ad9e6051e8921906faedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
