{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n"
     ]
    }
   ],
   "source": [
    "from carla import Benchmark\n",
    "import carla.evaluation.catalog as evaluation_catalog\n",
    "from carla.data.catalog import OnlineCatalog\n",
    "from carla.models.catalog import MLModelCatalog\n",
    "from carla.models.negative_instances import predict_negative_instances\n",
    "import carla.recourse_methods.catalog as recourse_catalog\n",
    "import shap \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from carla.data.causal_model import CausalModel\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from carla.data.catalog import CsvCatalog\n",
    "import numpy as np \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load Data \n",
    "dataframe = pd.read_csv('./census.csv', index_col=['Unnamed: 0'])\n",
    "continuous = dataframe.drop(columns=['target']).columns\n",
    "\n",
    "dataset = CsvCatalog(file_path=\"census.csv\",\n",
    "                     continuous=continuous,\n",
    "                     categorical=[],\n",
    "                     immutables=[],\n",
    "                     target='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance on test set 0.24078624078624078, balance on test set 0.2408794988330672\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.5545 Acc: 0.7574\n",
      "\n",
      "test Loss: 0.5530 Acc: 0.7591\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.5525 Acc: 0.7592\n",
      "\n",
      "test Loss: 0.5522 Acc: 0.7591\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.5526 Acc: 0.7592\n",
      "\n",
      "test Loss: 0.5525 Acc: 0.7591\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.5526 Acc: 0.7592\n",
      "\n",
      "test Loss: 0.5537 Acc: 0.7591\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.5525 Acc: 0.7592\n",
      "\n",
      "test Loss: 0.5531 Acc: 0.7591\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.5527 Acc: 0.7592\n",
      "\n",
      "test Loss: 0.5531 Acc: 0.7591\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.5524 Acc: 0.7592\n",
      "\n",
      "test Loss: 0.5525 Acc: 0.7591\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.5524 Acc: 0.7592\n",
      "\n",
      "test Loss: 0.5525 Acc: 0.7591\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.5523 Acc: 0.7592\n",
      "\n",
      "test Loss: 0.5561 Acc: 0.7591\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#Model \n",
    "\n",
    "training_params = {\"lr\": 0.01, \"epochs\": 10, \"batch_size\": 16, \"hidden_size\": [18, 9, 2]}\n",
    "\n",
    "ml_model = MLModelCatalog(\n",
    "    dataset, model_type=\"ann\", load_online=False, backend=\"pytorch\"\n",
    ")\n",
    "ml_model.train(\n",
    "    learning_rate=training_params[\"lr\"],\n",
    "    epochs=training_params[\"epochs\"],\n",
    "    batch_size=training_params[\"batch_size\"],\n",
    "    hidden_size=training_params[\"hidden_size\"],\n",
    "    force_train=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>Education-Num</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>...</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per week</th>\n",
       "      <th>Country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.479452</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.273973</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.205479</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.232877</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.205479</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.356164</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.246575</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.575342</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0       Age  Workclass  Education-Num  Marital Status  ...  \\\n",
       "0            0  0.301370      0.875       0.800000        0.666667  ...   \n",
       "1            1  0.452055      0.750       0.800000        0.333333  ...   \n",
       "2            2  0.287671      0.500       0.533333        0.000000  ...   \n",
       "3            3  0.493151      0.500       0.400000        0.333333  ...   \n",
       "4            4  0.150685      0.500       0.800000        0.333333  ...   \n",
       "6            6  0.438356      0.500       0.266667        0.500000  ...   \n",
       "7            7  0.479452      0.750       0.533333        0.333333  ...   \n",
       "10          10  0.273973      0.500       0.600000        0.333333  ...   \n",
       "11          11  0.178082      0.875       0.800000        0.333333  ...   \n",
       "12          12  0.082192      0.500       0.800000        0.666667  ...   \n",
       "13          13  0.205479      0.500       0.733333        0.666667  ...   \n",
       "14          14  0.315068      0.500       0.666667        0.333333  ...   \n",
       "15          15  0.232877      0.500       0.200000        0.333333  ...   \n",
       "16          16  0.109589      0.750       0.533333        0.666667  ...   \n",
       "17          17  0.205479      0.500       0.533333        0.666667  ...   \n",
       "18          18  0.287671      0.500       0.400000        0.333333  ...   \n",
       "19          19  0.356164      0.750       0.866667        0.000000  ...   \n",
       "21          21  0.506849      0.500       0.533333        0.833333  ...   \n",
       "22          22  0.246575      0.125       0.266667        0.333333  ...   \n",
       "24          24  0.575342      0.500       0.533333        0.000000  ...   \n",
       "\n",
       "    Capital Gain  Capital Loss  Hours per week   Country  target  \n",
       "0        0.02174           0.0        0.397959  0.951220   False  \n",
       "1        0.00000           0.0        0.122449  0.951220   False  \n",
       "2        0.00000           0.0        0.397959  0.951220   False  \n",
       "3        0.00000           0.0        0.397959  0.951220   False  \n",
       "4        0.00000           0.0        0.397959  0.121951   False  \n",
       "6        0.00000           0.0        0.153061  0.560976   False  \n",
       "7        0.00000           0.0        0.448980  0.951220    True  \n",
       "10       0.00000           0.0        0.806122  0.951220    True  \n",
       "11       0.00000           0.0        0.397959  0.463415    True  \n",
       "12       0.00000           0.0        0.295918  0.951220   False  \n",
       "13       0.00000           0.0        0.500000  0.951220   False  \n",
       "14       0.00000           0.0        0.397959  0.000000    True  \n",
       "15       0.00000           0.0        0.448980  0.634146   False  \n",
       "16       0.00000           0.0        0.346939  0.951220   False  \n",
       "17       0.00000           0.0        0.397959  0.951220   False  \n",
       "18       0.00000           0.0        0.500000  0.951220   False  \n",
       "19       0.00000           0.0        0.448980  0.951220    True  \n",
       "21       0.00000           0.0        0.193878  0.951220   False  \n",
       "22       0.00000           0.0        0.397959  0.951220   False  \n",
       "24       0.00000           0.0        0.397959  0.951220   False  \n",
       "\n",
       "[20 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from carla.models.negative_instances import predict_negative_instances\n",
    "import carla.recourse_methods.catalog as recourse_catalog\n",
    "\n",
    "factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "test_factual = factuals.iloc[:20]\n",
    "\n",
    "display(test_factual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Country</th>\n",
       "      <th>Education-Num</th>\n",
       "      <th>...</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Race</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Workclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.321253</td>\n",
       "      <td>0.041626</td>\n",
       "      <td>0.019884</td>\n",
       "      <td>0.971023</td>\n",
       "      <td>0.819885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>1.019861</td>\n",
       "      <td>0.180117</td>\n",
       "      <td>1.019876</td>\n",
       "      <td>0.855121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.433441</td>\n",
       "      <td>0.019730</td>\n",
       "      <td>0.019524</td>\n",
       "      <td>0.969146</td>\n",
       "      <td>0.819586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268744</td>\n",
       "      <td>1.019357</td>\n",
       "      <td>-0.019814</td>\n",
       "      <td>1.019600</td>\n",
       "      <td>0.731458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.327238</td>\n",
       "      <td>0.039574</td>\n",
       "      <td>0.039561</td>\n",
       "      <td>0.973703</td>\n",
       "      <td>0.572905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389423</td>\n",
       "      <td>0.960569</td>\n",
       "      <td>0.160431</td>\n",
       "      <td>1.039407</td>\n",
       "      <td>0.460457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.444136</td>\n",
       "      <td>0.049175</td>\n",
       "      <td>0.049167</td>\n",
       "      <td>1.000205</td>\n",
       "      <td>0.449170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425017</td>\n",
       "      <td>0.549104</td>\n",
       "      <td>-0.049163</td>\n",
       "      <td>1.049120</td>\n",
       "      <td>0.450853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.170553</td>\n",
       "      <td>0.019870</td>\n",
       "      <td>0.019867</td>\n",
       "      <td>0.141789</td>\n",
       "      <td>0.819868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694727</td>\n",
       "      <td>0.519853</td>\n",
       "      <td>1.019867</td>\n",
       "      <td>0.019796</td>\n",
       "      <td>0.480160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.531572</td>\n",
       "      <td>0.109336</td>\n",
       "      <td>0.110005</td>\n",
       "      <td>0.518167</td>\n",
       "      <td>0.376740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656975</td>\n",
       "      <td>0.609418</td>\n",
       "      <td>0.102082</td>\n",
       "      <td>0.107207</td>\n",
       "      <td>0.390516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.449858</td>\n",
       "      <td>0.029691</td>\n",
       "      <td>0.029686</td>\n",
       "      <td>0.980796</td>\n",
       "      <td>0.563021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286764</td>\n",
       "      <td>1.029648</td>\n",
       "      <td>-0.029684</td>\n",
       "      <td>1.029658</td>\n",
       "      <td>0.720326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.293862</td>\n",
       "      <td>0.019742</td>\n",
       "      <td>0.019774</td>\n",
       "      <td>0.970975</td>\n",
       "      <td>0.619771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266085</td>\n",
       "      <td>0.519780</td>\n",
       "      <td>-0.019705</td>\n",
       "      <td>1.019730</td>\n",
       "      <td>0.480168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.196203</td>\n",
       "      <td>0.019219</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>0.481628</td>\n",
       "      <td>0.819097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.724943</td>\n",
       "      <td>0.268447</td>\n",
       "      <td>-0.019749</td>\n",
       "      <td>1.018087</td>\n",
       "      <td>0.855502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.141745</td>\n",
       "      <td>0.059902</td>\n",
       "      <td>0.059928</td>\n",
       "      <td>1.010545</td>\n",
       "      <td>0.859933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095980</td>\n",
       "      <td>1.059632</td>\n",
       "      <td>0.656273</td>\n",
       "      <td>0.059933</td>\n",
       "      <td>0.440109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.242659</td>\n",
       "      <td>0.038782</td>\n",
       "      <td>0.039105</td>\n",
       "      <td>0.984822</td>\n",
       "      <td>0.772333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891980</td>\n",
       "      <td>0.538787</td>\n",
       "      <td>0.161057</td>\n",
       "      <td>1.032328</td>\n",
       "      <td>0.460242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.295213</td>\n",
       "      <td>0.019901</td>\n",
       "      <td>0.019899</td>\n",
       "      <td>0.019847</td>\n",
       "      <td>0.686566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220776</td>\n",
       "      <td>0.269881</td>\n",
       "      <td>-0.019898</td>\n",
       "      <td>1.019886</td>\n",
       "      <td>0.480107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.301737</td>\n",
       "      <td>0.079172</td>\n",
       "      <td>0.079216</td>\n",
       "      <td>0.590150</td>\n",
       "      <td>0.278992</td>\n",
       "      <td>...</td>\n",
       "      <td>1.045171</td>\n",
       "      <td>0.077582</td>\n",
       "      <td>-0.075659</td>\n",
       "      <td>0.992672</td>\n",
       "      <td>0.421349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.188768</td>\n",
       "      <td>0.079506</td>\n",
       "      <td>0.078872</td>\n",
       "      <td>1.025127</td>\n",
       "      <td>0.613551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407132</td>\n",
       "      <td>1.079367</td>\n",
       "      <td>0.589541</td>\n",
       "      <td>0.929185</td>\n",
       "      <td>0.670641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.264356</td>\n",
       "      <td>0.059392</td>\n",
       "      <td>0.059493</td>\n",
       "      <td>1.006764</td>\n",
       "      <td>0.592796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547477</td>\n",
       "      <td>1.059534</td>\n",
       "      <td>0.859549</td>\n",
       "      <td>0.941456</td>\n",
       "      <td>0.440443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.319327</td>\n",
       "      <td>0.038134</td>\n",
       "      <td>0.038593</td>\n",
       "      <td>0.959100</td>\n",
       "      <td>0.437696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857231</td>\n",
       "      <td>1.036447</td>\n",
       "      <td>-0.038722</td>\n",
       "      <td>1.018505</td>\n",
       "      <td>0.460867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.360109</td>\n",
       "      <td>0.029535</td>\n",
       "      <td>0.029375</td>\n",
       "      <td>0.929531</td>\n",
       "      <td>0.896107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285127</td>\n",
       "      <td>1.027303</td>\n",
       "      <td>0.829973</td>\n",
       "      <td>0.029022</td>\n",
       "      <td>0.720361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.591711</td>\n",
       "      <td>0.089236</td>\n",
       "      <td>0.089385</td>\n",
       "      <td>0.869271</td>\n",
       "      <td>0.622438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631122</td>\n",
       "      <td>0.589525</td>\n",
       "      <td>0.889324</td>\n",
       "      <td>0.088220</td>\n",
       "      <td>0.411134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.295149</td>\n",
       "      <td>0.049071</td>\n",
       "      <td>0.049346</td>\n",
       "      <td>0.916496</td>\n",
       "      <td>0.316192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398115</td>\n",
       "      <td>0.549609</td>\n",
       "      <td>-0.047718</td>\n",
       "      <td>1.040757</td>\n",
       "      <td>0.075434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.516166</td>\n",
       "      <td>0.059390</td>\n",
       "      <td>0.059381</td>\n",
       "      <td>0.891925</td>\n",
       "      <td>0.592720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987406</td>\n",
       "      <td>1.059338</td>\n",
       "      <td>0.859383</td>\n",
       "      <td>0.059365</td>\n",
       "      <td>0.440642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age  Capital Gain  Capital Loss   Country  Education-Num  ...  \\\n",
       "0   0.321253      0.041626      0.019884  0.971023       0.819885  ...   \n",
       "1   0.433441      0.019730      0.019524  0.969146       0.819586  ...   \n",
       "2   0.327238      0.039574      0.039561  0.973703       0.572905  ...   \n",
       "3   0.444136      0.049175      0.049167  1.000205       0.449170  ...   \n",
       "4   0.170553      0.019870      0.019867  0.141789       0.819868  ...   \n",
       "6   0.531572      0.109336      0.110005  0.518167       0.376740  ...   \n",
       "7   0.449858      0.029691      0.029686  0.980796       0.563021  ...   \n",
       "10  0.293862      0.019742      0.019774  0.970975       0.619771  ...   \n",
       "11  0.196203      0.019219      0.019444  0.481628       0.819097  ...   \n",
       "12  0.141745      0.059902      0.059928  1.010545       0.859933  ...   \n",
       "13  0.242659      0.038782      0.039105  0.984822       0.772333  ...   \n",
       "14  0.295213      0.019901      0.019899  0.019847       0.686566  ...   \n",
       "15  0.301737      0.079172      0.079216  0.590150       0.278992  ...   \n",
       "16  0.188768      0.079506      0.078872  1.025127       0.613551  ...   \n",
       "17  0.264356      0.059392      0.059493  1.006764       0.592796  ...   \n",
       "18  0.319327      0.038134      0.038593  0.959100       0.437696  ...   \n",
       "19  0.360109      0.029535      0.029375  0.929531       0.896107  ...   \n",
       "21  0.591711      0.089236      0.089385  0.869271       0.622438  ...   \n",
       "22  0.295149      0.049071      0.049346  0.916496       0.316192  ...   \n",
       "24  0.516166      0.059390      0.059381  0.891925       0.592720  ...   \n",
       "\n",
       "    Occupation      Race  Relationship       Sex  Workclass  \n",
       "0     0.091200  1.019861      0.180117  1.019876   0.855121  \n",
       "1     0.268744  1.019357     -0.019814  1.019600   0.731458  \n",
       "2     0.389423  0.960569      0.160431  1.039407   0.460457  \n",
       "3     0.425017  0.549104     -0.049163  1.049120   0.450853  \n",
       "4     0.694727  0.519853      1.019867  0.019796   0.480160  \n",
       "6     0.656975  0.609418      0.102082  0.107207   0.390516  \n",
       "7     0.286764  1.029648     -0.029684  1.029658   0.720326  \n",
       "10    0.266085  0.519780     -0.019705  1.019730   0.480168  \n",
       "11    0.724943  0.268447     -0.019749  1.018087   0.855502  \n",
       "12    0.095980  1.059632      0.656273  0.059933   0.440109  \n",
       "13    0.891980  0.538787      0.161057  1.032328   0.460242  \n",
       "14    0.220776  0.269881     -0.019898  1.019886   0.480107  \n",
       "15    1.045171  0.077582     -0.075659  0.992672   0.421349  \n",
       "16    0.407132  1.079367      0.589541  0.929185   0.670641  \n",
       "17    0.547477  1.059534      0.859549  0.941456   0.440443  \n",
       "18    0.857231  1.036447     -0.038722  1.018505   0.460867  \n",
       "19    0.285127  1.027303      0.829973  0.029022   0.720361  \n",
       "21    0.631122  0.589525      0.889324  0.088220   0.411134  \n",
       "22    0.398115  0.549609     -0.047718  1.040757   0.075434  \n",
       "24    0.987406  1.059338      0.859383  0.059365   0.440642  \n",
       "\n",
       "[20 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyperparams = {\"loss_type\": \"BCE\", \"binary_cat_features\": True}\n",
    "\n",
    "recourse_method = recourse_catalog.Wachter(ml_model, hyperparams)\n",
    "df_cfs = recourse_method.get_counterfactuals(test_factual)\n",
    "\n",
    "display(df_cfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict={\n",
    "    \"u1\": \"Sex\",\n",
    "    \"u2\": \"Race\",\n",
    "    \"u3\": \"Age\",\n",
    "    \"u4\": \"Relationship\",\n",
    "    \"u5\": \"Hours per week\",\n",
    "    \"u6\": \"Capital Gain\",\n",
    "    \"u7\": \"Education-Num\",\n",
    "    \"u8\": \"Occupation\",\n",
    "    \"u9\": \"target\",}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_from_causal(scm,values,cf_label, mapping_dict):\n",
    "    values['target']=cf_label\n",
    "    def _get_noise_string(node):\n",
    "        def _get_node_id(node):\n",
    "            return node[1:]\n",
    "        if not node[0] == \"x\":\n",
    "            raise ValueError\n",
    "        return \"u\" + _get_node_id(node)\n",
    "    exogenous_variables = np.concatenate(\n",
    "        [\n",
    "            np.array(values[mapping_dict[node]]).reshape(-1, 1)\n",
    "            for node in scm.get_topological_ordering(\"exogenous\")\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    exogenous_variables = pd.DataFrame(\n",
    "        exogenous_variables, columns=scm.get_topological_ordering(\"exogenous\")\n",
    "    )\n",
    "\n",
    "    endogenous_variables = exogenous_variables.copy()\n",
    "    endogenous_variables = endogenous_variables.rename(\n",
    "        columns=dict(\n",
    "            zip(\n",
    "                scm.get_topological_ordering(\"exogenous\"),\n",
    "                scm.get_topological_ordering(\"endogenous\"),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    # used later to make sure parents are populated when computing children\n",
    "    endogenous_variables.loc[:] = np.nan\n",
    "    for node in scm.get_topological_ordering(\"endogenous\"):\n",
    "        parents = scm.get_parents(node)\n",
    "        if endogenous_variables.loc[:, list(parents)].isnull().values.any():\n",
    "            raise ValueError(\n",
    "                \"parents in endogenous_variables should already be occupied\"\n",
    "            )\n",
    "        endogenous_variables[node] = scm.structural_equations_np[node](\n",
    "            exogenous_variables[_get_noise_string(node)],\n",
    "            *[endogenous_variables[p] for p in parents],\n",
    "        )\n",
    "    print(endogenous_variables)\n",
    "    labels=endogenous_variables['x9']\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adult Model Initiate\n",
      "Structural Equation Finished\n",
      "Noise Distribution Finished\n",
      "Finished Loading\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "Remove Prefix\n",
      "End Prefix\n",
      "{'x1': <function adult_model.<locals>.<lambda> at 0x7fe0afe21710>, 'x2': <function adult_model.<locals>.<lambda> at 0x7fe0afe219e0>, 'x3': <function adult_model.<locals>.<lambda> at 0x7fe0afe21a70>, 'x4': <function adult_model.<locals>.<lambda> at 0x7fe0afe21b00>, 'x5': <function adult_model.<locals>.<lambda> at 0x7fe0afe21b90>, 'x6': <function adult_model.<locals>.<lambda> at 0x7fe0afe21c20>, 'x7': <function adult_model.<locals>.<lambda> at 0x7fe0afe21cb0>, 'x8': <function adult_model.<locals>.<lambda> at 0x7fe0afe21d40>, 'x9': <function adult_model.<locals>.<lambda> at 0x7fe0afe21dd0>}\n",
      "         x1        x2        x3        x7      x8        x4        x5  \\\n",
      "0  1.019876  1.019861  0.321253  0.819885  0.0912  0.200515  0.428042   \n",
      "\n",
      "         x6        x9  \n",
      "0  0.058811 -0.003363  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10137/1870873325.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructural_equations_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSematic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mml_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_cfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmapping_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m ''' \n\u001b[1;32m     29\u001b[0m \u001b[0mAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10137/1870873325.py\u001b[0m in \u001b[0;36mget_evaluation\u001b[0;34m(self, factual, counterfactual, causal_model)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mcf_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcf_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcausal_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_pred_from_causal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcausal_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcounterfactual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcf_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcf_label\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0mcausal_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m         raise ValueError(\n\u001b[0;32m-> 1330\u001b[0;31m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "from carla.data import causal_model\n",
    "from carla.evaluation import remove_nans\n",
    "from carla.evaluation.api import Evaluation\n",
    "class Sematic(Evaluation):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ml_model, causal_graph):\n",
    "        self.ml_model= ml_model\n",
    "        self.causal_graph=causal_graph\n",
    "    def get_evaluation(self,factual: np.ndarray, counterfactual: np.ndarray, causal_model):\n",
    "        # generate data \n",
    "        cf_label=self.ml_model.predict(np.array(counterfactual.values).reshape(1,-1))\n",
    "        cf_label=np.argmax(cf_label)\n",
    "        causal_label=get_pred_from_causal(self.causal_graph,counterfactual,cf_label, mapping_dict)\n",
    "        print(cf_label)\n",
    "        if cf_label ==causal_label:\n",
    "            return 1 \n",
    "        else: \n",
    "            return 0\n",
    "\n",
    "class path_checker():\n",
    "    pass\n",
    "\n",
    "scm = CausalModel(\"adult\")\n",
    "print(scm.structural_equations_np)\n",
    "metric = Sematic(ml_model,scm)\n",
    "result=metric.get_evaluation(np.array([]),df_cfs.iloc[0],mapping_dict)\n",
    "''' \n",
    "Analysis\n",
    "Probitlity Distributions \n",
    "Histogram True Positive, False Positives \n",
    "'''\n",
    "'''\n",
    "Parts of counterfactuals actually change \n",
    "1hop and 2 hop relations \n",
    "'''\n",
    "'''Histogram Features / true Positive / false Positive'''\n",
    "# first initialize the benchmarking class by passing\n",
    "# black-box-model, recourse method, and factuals into it\n",
    "#benchmark = Benchmark(ml_model, recourse_method, factuals)\n",
    "\n",
    "# now you can decide if you want to run all measurements\n",
    "# or just specific ones.\n",
    "#evaluation_measures = [\n",
    "#    evaluation_catalog.YNN(benchmark.mlmodel, {\"y\": 5, \"cf_label\": 1}),\n",
    "#    evaluation_catalog.Distance(benchmark.mlmodel),\n",
    "#    evaluation_catalog.SuccessRate(),\n",
    "#    evaluation_catalog.Redundancy(benchmark.mlmodel, {\"cf_label\": 1}),\n",
    "#    evaluation_catalog.ConstraintViolation(benchmark.mlmodel),\n",
    "#    evaluation_catalog.AvgTime({\"time\": benchmark.timer}),\n",
    "#]\n",
    "\n",
    "# now run all implemented measurements and create a\n",
    "# DataFrame which consists of all results\n",
    "#results = benchmark.run_benchmark(evaluation_measures)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('CARLA-koH0yuP4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f55703f6f29bf5b3ae6360c8e9dbcc23e2b3226583ad9e6051e8921906faedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
