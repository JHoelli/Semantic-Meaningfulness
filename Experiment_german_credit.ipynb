{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n"
     ]
    }
   ],
   "source": [
    "from carla import Benchmark\n",
    "from IPython.display import display\n",
    "import carla.evaluation.catalog as evaluation_catalog\n",
    "from carla.data.catalog import OnlineCatalog\n",
    "from carla.models.catalog import MLModelCatalog\n",
    "from carla.models.negative_instances import predict_negative_instances\n",
    "import carla.recourse_methods.catalog as recourse_catalog\n",
    "import shap \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from carla.data.causal_model import CausalModel\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from carla.data.catalog import CsvCatalog\n",
    "import numpy as np \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x6</th>\n",
       "      <th>x5</th>\n",
       "      <th>x7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.901628</td>\n",
       "      <td>0.069036</td>\n",
       "      <td>3.422301</td>\n",
       "      <td>1.637961</td>\n",
       "      <td>0.593002</td>\n",
       "      <td>-2.128538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.152467</td>\n",
       "      <td>-0.081706</td>\n",
       "      <td>-0.055258</td>\n",
       "      <td>-1.595548</td>\n",
       "      <td>0.480908</td>\n",
       "      <td>2.487011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.102632</td>\n",
       "      <td>-0.206645</td>\n",
       "      <td>2.465405</td>\n",
       "      <td>2.844562</td>\n",
       "      <td>5.338350</td>\n",
       "      <td>-5.896902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.374361</td>\n",
       "      <td>-0.134668</td>\n",
       "      <td>0.112714</td>\n",
       "      <td>1.412981</td>\n",
       "      <td>1.394632</td>\n",
       "      <td>-7.577527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.021415</td>\n",
       "      <td>0.030820</td>\n",
       "      <td>4.122077</td>\n",
       "      <td>0.107332</td>\n",
       "      <td>3.838096</td>\n",
       "      <td>-2.995881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.753303</td>\n",
       "      <td>-0.018339</td>\n",
       "      <td>1.108545</td>\n",
       "      <td>-3.506350</td>\n",
       "      <td>-0.588439</td>\n",
       "      <td>0.758632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.061453</td>\n",
       "      <td>0.119317</td>\n",
       "      <td>0.613308</td>\n",
       "      <td>-0.231908</td>\n",
       "      <td>1.068151</td>\n",
       "      <td>-8.115625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.365306</td>\n",
       "      <td>0.083312</td>\n",
       "      <td>-0.925692</td>\n",
       "      <td>8.535162</td>\n",
       "      <td>2.829978</td>\n",
       "      <td>10.365376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.266146</td>\n",
       "      <td>-0.004838</td>\n",
       "      <td>-2.754319</td>\n",
       "      <td>-5.475563</td>\n",
       "      <td>0.167984</td>\n",
       "      <td>-3.749375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.792152</td>\n",
       "      <td>-0.272724</td>\n",
       "      <td>-0.559442</td>\n",
       "      <td>-3.006235</td>\n",
       "      <td>-2.528264</td>\n",
       "      <td>-0.974836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label   x1         x2        x3        x4        x6        x5         x7\n",
       "0      0.0  1.0  -2.901628  0.069036  3.422301  1.637961  0.593002  -2.128538\n",
       "1      1.0  0.0   7.152467 -0.081706 -0.055258 -1.595548  0.480908   2.487011\n",
       "2      1.0  0.0   4.102632 -0.206645  2.465405  2.844562  5.338350  -5.896902\n",
       "3      1.0  1.0   7.374361 -0.134668  0.112714  1.412981  1.394632  -7.577527\n",
       "4      0.0  1.0   2.021415  0.030820  4.122077  0.107332  3.838096  -2.995881\n",
       "..     ...  ...        ...       ...       ...       ...       ...        ...\n",
       "995    0.0  0.0  -9.753303 -0.018339  1.108545 -3.506350 -0.588439   0.758632\n",
       "996    0.0  1.0  -3.061453  0.119317  0.613308 -0.231908  1.068151  -8.115625\n",
       "997    1.0  1.0   3.365306  0.083312 -0.925692  8.535162  2.829978  10.365376\n",
       "998    0.0  0.0 -13.266146 -0.004838 -2.754319 -5.475563  0.167984  -3.749375\n",
       "999    0.0  0.0 -15.792152 -0.272724 -0.559442 -3.006235 -2.528264  -0.974836\n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scm = CausalModel(\"credit\")\n",
    "dataset = scm.generate_dataset(1000)\n",
    "dataset.df.to_csv('credit_synthetic.csv',index=False)\n",
    "display(dataset.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Build Dataset for Wachter'''\n",
    "import pandas as pd\n",
    "# Load Data \n",
    "dataframe = pd.read_csv('./credit_synthetic.csv')\n",
    "continuous = dataframe.drop(columns=['label']).columns\n",
    "\n",
    "dataset = CsvCatalog(file_path=\"credit_synthetic.csv\",\n",
    "                     continuous=continuous,\n",
    "                     categorical=[],\n",
    "                     immutables=[],\n",
    "                     target='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance on test set 0.452, balance on test set 0.504\n",
      "Epoch 0/2\n",
      "----------\n",
      "train Loss: 0.6853 Acc: 0.5760\n",
      "\n",
      "test Loss: 0.6499 Acc: 0.7040\n",
      "\n",
      "Epoch 1/2\n",
      "----------\n",
      "train Loss: 0.5656 Acc: 0.7293\n",
      "\n",
      "test Loss: 0.5095 Acc: 0.8040\n",
      "\n",
      "Epoch 2/2\n",
      "----------\n",
      "train Loss: 0.4747 Acc: 0.8093\n",
      "\n",
      "test Loss: 0.5793 Acc: 0.7000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model \n",
    "\n",
    "training_params = {\"lr\": 0.01, \"epochs\": 3, \"batch_size\": 16, \"hidden_size\": [18, 9, 2]}\n",
    "\n",
    "ml_model = MLModelCatalog(\n",
    "    dataset, model_type=\"ann\", load_online=False, backend=\"pytorch\"\n",
    ")\n",
    "ml_model.train(\n",
    "    learning_rate=training_params[\"lr\"],\n",
    "    epochs=training_params[\"epochs\"],\n",
    "    batch_size=training_params[\"batch_size\"],\n",
    "    hidden_size=training_params[\"hidden_size\"],\n",
    "    force_train=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x6</th>\n",
       "      <th>x5</th>\n",
       "      <th>x7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.150878</td>\n",
       "      <td>0.257247</td>\n",
       "      <td>0.564962</td>\n",
       "      <td>0.586630</td>\n",
       "      <td>0.193796</td>\n",
       "      <td>0.791498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139977</td>\n",
       "      <td>0.473798</td>\n",
       "      <td>0.703149</td>\n",
       "      <td>0.506172</td>\n",
       "      <td>0.160075</td>\n",
       "      <td>0.486864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236518</td>\n",
       "      <td>0.330420</td>\n",
       "      <td>0.769651</td>\n",
       "      <td>0.431542</td>\n",
       "      <td>0.547872</td>\n",
       "      <td>0.192275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.098774</td>\n",
       "      <td>0.736847</td>\n",
       "      <td>0.601899</td>\n",
       "      <td>0.277447</td>\n",
       "      <td>0.479366</td>\n",
       "      <td>0.553057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223250</td>\n",
       "      <td>0.283348</td>\n",
       "      <td>0.656265</td>\n",
       "      <td>0.211635</td>\n",
       "      <td>0.478846</td>\n",
       "      <td>0.547856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186938</td>\n",
       "      <td>0.324934</td>\n",
       "      <td>0.744256</td>\n",
       "      <td>0.423261</td>\n",
       "      <td>0.410593</td>\n",
       "      <td>0.508765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235098</td>\n",
       "      <td>0.441379</td>\n",
       "      <td>0.662188</td>\n",
       "      <td>0.308735</td>\n",
       "      <td>0.223921</td>\n",
       "      <td>0.339314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223860</td>\n",
       "      <td>0.650618</td>\n",
       "      <td>0.618316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490678</td>\n",
       "      <td>0.115417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.207427</td>\n",
       "      <td>0.195322</td>\n",
       "      <td>0.713388</td>\n",
       "      <td>0.445506</td>\n",
       "      <td>0.510982</td>\n",
       "      <td>0.578401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.183681</td>\n",
       "      <td>0.383227</td>\n",
       "      <td>0.851397</td>\n",
       "      <td>0.572500</td>\n",
       "      <td>0.460002</td>\n",
       "      <td>0.400448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230408</td>\n",
       "      <td>0.168350</td>\n",
       "      <td>0.657713</td>\n",
       "      <td>0.265026</td>\n",
       "      <td>0.212147</td>\n",
       "      <td>0.427082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.195330</td>\n",
       "      <td>0.579694</td>\n",
       "      <td>0.561233</td>\n",
       "      <td>0.415300</td>\n",
       "      <td>0.342835</td>\n",
       "      <td>0.233115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.196048</td>\n",
       "      <td>0.446326</td>\n",
       "      <td>0.774702</td>\n",
       "      <td>0.512823</td>\n",
       "      <td>0.454425</td>\n",
       "      <td>0.330478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277483</td>\n",
       "      <td>0.403973</td>\n",
       "      <td>0.753703</td>\n",
       "      <td>0.333518</td>\n",
       "      <td>0.344844</td>\n",
       "      <td>0.557853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.239666</td>\n",
       "      <td>0.106824</td>\n",
       "      <td>0.678120</td>\n",
       "      <td>0.520559</td>\n",
       "      <td>0.413108</td>\n",
       "      <td>0.288689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>0.166494</td>\n",
       "      <td>0.718967</td>\n",
       "      <td>0.269984</td>\n",
       "      <td>0.495010</td>\n",
       "      <td>0.567638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.162627</td>\n",
       "      <td>0.376727</td>\n",
       "      <td>0.704628</td>\n",
       "      <td>0.434699</td>\n",
       "      <td>0.265723</td>\n",
       "      <td>0.515658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.185598</td>\n",
       "      <td>0.527006</td>\n",
       "      <td>0.735416</td>\n",
       "      <td>0.492822</td>\n",
       "      <td>0.304649</td>\n",
       "      <td>0.345451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199407</td>\n",
       "      <td>0.237350</td>\n",
       "      <td>0.621213</td>\n",
       "      <td>0.435223</td>\n",
       "      <td>0.492766</td>\n",
       "      <td>0.562327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089577</td>\n",
       "      <td>0.372860</td>\n",
       "      <td>0.563108</td>\n",
       "      <td>0.302963</td>\n",
       "      <td>0.280643</td>\n",
       "      <td>0.493610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label   x1        x2        x3        x4        x6        x5        x7\n",
       "7      0.0  1.0  0.150878  0.257247  0.564962  0.586630  0.193796  0.791498\n",
       "12     0.0  0.0  0.139977  0.473798  0.703149  0.506172  0.160075  0.486864\n",
       "19     0.0  0.0  0.236518  0.330420  0.769651  0.431542  0.547872  0.192275\n",
       "30     0.0  1.0  0.098774  0.736847  0.601899  0.277447  0.479366  0.553057\n",
       "32     0.0  0.0  0.223250  0.283348  0.656265  0.211635  0.478846  0.547856\n",
       "33     0.0  0.0  0.186938  0.324934  0.744256  0.423261  0.410593  0.508765\n",
       "36     0.0  0.0  0.235098  0.441379  0.662188  0.308735  0.223921  0.339314\n",
       "37     0.0  0.0  0.223860  0.650618  0.618316  0.000000  0.490678  0.115417\n",
       "40     0.0  0.0  0.207427  0.195322  0.713388  0.445506  0.510982  0.578401\n",
       "48     0.0  1.0  0.183681  0.383227  0.851397  0.572500  0.460002  0.400448\n",
       "53     0.0  0.0  0.230408  0.168350  0.657713  0.265026  0.212147  0.427082\n",
       "55     0.0  0.0  0.195330  0.579694  0.561233  0.415300  0.342835  0.233115\n",
       "57     0.0  1.0  0.196048  0.446326  0.774702  0.512823  0.454425  0.330478\n",
       "62     0.0  0.0  0.277483  0.403973  0.753703  0.333518  0.344844  0.557853\n",
       "70     0.0  0.0  0.239666  0.106824  0.678120  0.520559  0.413108  0.288689\n",
       "74     0.0  0.0  0.259511  0.166494  0.718967  0.269984  0.495010  0.567638\n",
       "76     0.0  0.0  0.162627  0.376727  0.704628  0.434699  0.265723  0.515658\n",
       "78     1.0  1.0  0.185598  0.527006  0.735416  0.492822  0.304649  0.345451\n",
       "90     1.0  0.0  0.199407  0.237350  0.621213  0.435223  0.492766  0.562327\n",
       "105    0.0  0.0  0.089577  0.372860  0.563108  0.302963  0.280643  0.493610"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from carla.models.negative_instances import predict_negative_instances\n",
    "import carla.recourse_methods.catalog as recourse_catalog\n",
    "\n",
    "factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "test_factual = factuals.iloc[:20]\n",
    "\n",
    "display(test_factual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.010000</td>\n",
       "      <td>0.160878</td>\n",
       "      <td>0.267247</td>\n",
       "      <td>0.554962</td>\n",
       "      <td>0.203796</td>\n",
       "      <td>0.596630</td>\n",
       "      <td>0.801498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.088494</td>\n",
       "      <td>0.228526</td>\n",
       "      <td>0.562308</td>\n",
       "      <td>0.614642</td>\n",
       "      <td>0.248615</td>\n",
       "      <td>0.594692</td>\n",
       "      <td>0.575398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.038755</td>\n",
       "      <td>0.276136</td>\n",
       "      <td>0.369862</td>\n",
       "      <td>0.730123</td>\n",
       "      <td>0.587473</td>\n",
       "      <td>0.471266</td>\n",
       "      <td>0.232008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.975852</td>\n",
       "      <td>0.128665</td>\n",
       "      <td>0.766715</td>\n",
       "      <td>0.572029</td>\n",
       "      <td>0.509253</td>\n",
       "      <td>0.307331</td>\n",
       "      <td>0.582945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.019950</td>\n",
       "      <td>0.243207</td>\n",
       "      <td>0.303300</td>\n",
       "      <td>0.636314</td>\n",
       "      <td>0.498802</td>\n",
       "      <td>0.231588</td>\n",
       "      <td>0.567812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.039692</td>\n",
       "      <td>0.226655</td>\n",
       "      <td>0.364634</td>\n",
       "      <td>0.704558</td>\n",
       "      <td>0.450306</td>\n",
       "      <td>0.462965</td>\n",
       "      <td>0.548475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.078511</td>\n",
       "      <td>0.313666</td>\n",
       "      <td>0.519907</td>\n",
       "      <td>0.583664</td>\n",
       "      <td>0.302480</td>\n",
       "      <td>0.387273</td>\n",
       "      <td>0.417866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.013175</td>\n",
       "      <td>0.313035</td>\n",
       "      <td>0.738475</td>\n",
       "      <td>0.530253</td>\n",
       "      <td>0.579792</td>\n",
       "      <td>0.082588</td>\n",
       "      <td>0.202939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.217427</td>\n",
       "      <td>0.205322</td>\n",
       "      <td>0.703388</td>\n",
       "      <td>0.520982</td>\n",
       "      <td>0.455506</td>\n",
       "      <td>0.588401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.983039</td>\n",
       "      <td>0.203645</td>\n",
       "      <td>0.403180</td>\n",
       "      <td>0.831444</td>\n",
       "      <td>0.479964</td>\n",
       "      <td>0.592461</td>\n",
       "      <td>0.420410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.088798</td>\n",
       "      <td>0.319736</td>\n",
       "      <td>0.257796</td>\n",
       "      <td>0.568538</td>\n",
       "      <td>0.301594</td>\n",
       "      <td>0.354557</td>\n",
       "      <td>0.516478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.055028</td>\n",
       "      <td>0.254354</td>\n",
       "      <td>0.638006</td>\n",
       "      <td>0.502535</td>\n",
       "      <td>0.401802</td>\n",
       "      <td>0.474806</td>\n",
       "      <td>0.292637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.976763</td>\n",
       "      <td>0.225927</td>\n",
       "      <td>0.476179</td>\n",
       "      <td>0.744847</td>\n",
       "      <td>0.484300</td>\n",
       "      <td>0.542694</td>\n",
       "      <td>0.360353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.287483</td>\n",
       "      <td>0.413973</td>\n",
       "      <td>0.743703</td>\n",
       "      <td>0.354844</td>\n",
       "      <td>0.343518</td>\n",
       "      <td>0.567853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.049465</td>\n",
       "      <td>0.289165</td>\n",
       "      <td>0.156300</td>\n",
       "      <td>0.628647</td>\n",
       "      <td>0.462602</td>\n",
       "      <td>0.570040</td>\n",
       "      <td>0.338179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.269511</td>\n",
       "      <td>0.176494</td>\n",
       "      <td>0.708967</td>\n",
       "      <td>0.505010</td>\n",
       "      <td>0.279984</td>\n",
       "      <td>0.577638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.069005</td>\n",
       "      <td>0.231677</td>\n",
       "      <td>0.445746</td>\n",
       "      <td>0.635612</td>\n",
       "      <td>0.334767</td>\n",
       "      <td>0.503726</td>\n",
       "      <td>0.584696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.961745</td>\n",
       "      <td>0.235181</td>\n",
       "      <td>0.576541</td>\n",
       "      <td>0.685878</td>\n",
       "      <td>0.354224</td>\n",
       "      <td>0.542389</td>\n",
       "      <td>0.395027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.209407</td>\n",
       "      <td>0.247350</td>\n",
       "      <td>0.611213</td>\n",
       "      <td>0.502766</td>\n",
       "      <td>0.445223</td>\n",
       "      <td>0.572327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.107889</td>\n",
       "      <td>0.198742</td>\n",
       "      <td>0.482091</td>\n",
       "      <td>0.454164</td>\n",
       "      <td>0.389876</td>\n",
       "      <td>0.411338</td>\n",
       "      <td>0.602806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2        x3        x4        x5        x6        x7\n",
       "7    1.010000  0.160878  0.267247  0.554962  0.203796  0.596630  0.801498\n",
       "12   0.088494  0.228526  0.562308  0.614642  0.248615  0.594692  0.575398\n",
       "19   0.038755  0.276136  0.369862  0.730123  0.587473  0.471266  0.232008\n",
       "30   0.975852  0.128665  0.766715  0.572029  0.509253  0.307331  0.582945\n",
       "32   0.019950  0.243207  0.303300  0.636314  0.498802  0.231588  0.567812\n",
       "33   0.039692  0.226655  0.364634  0.704558  0.450306  0.462965  0.548475\n",
       "36   0.078511  0.313666  0.519907  0.583664  0.302480  0.387273  0.417866\n",
       "37   0.013175  0.313035  0.738475  0.530253  0.579792  0.082588  0.202939\n",
       "40   0.010000  0.217427  0.205322  0.703388  0.520982  0.455506  0.588401\n",
       "48   0.983039  0.203645  0.403180  0.831444  0.479964  0.592461  0.420410\n",
       "53   0.088798  0.319736  0.257796  0.568538  0.301594  0.354557  0.516478\n",
       "55   0.055028  0.254354  0.638006  0.502535  0.401802  0.474806  0.292637\n",
       "57   0.976763  0.225927  0.476179  0.744847  0.484300  0.542694  0.360353\n",
       "62   0.010000  0.287483  0.413973  0.743703  0.354844  0.343518  0.567853\n",
       "70   0.049465  0.289165  0.156300  0.628647  0.462602  0.570040  0.338179\n",
       "74   0.010000  0.269511  0.176494  0.708967  0.505010  0.279984  0.577638\n",
       "76   0.069005  0.231677  0.445746  0.635612  0.334767  0.503726  0.584696\n",
       "78   0.961745  0.235181  0.576541  0.685878  0.354224  0.542389  0.395027\n",
       "90   0.010000  0.209407  0.247350  0.611213  0.502766  0.445223  0.572327\n",
       "105  0.107889  0.198742  0.482091  0.454164  0.389876  0.411338  0.602806"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyperparams = {\"loss_type\": \"BCE\"}\n",
    "\n",
    "recourse_method = recourse_catalog.Wachter(ml_model, hyperparams)\n",
    "cfs = recourse_method.get_counterfactuals(test_factual)\n",
    "#from carla.models.negative_instances import predict_negative_instances\n",
    "#from carla.recourse_methods.catalog.causal_recourse import (\n",
    "#    CausalRecourse,\n",
    "#    constraints,\n",
    "#    samplers,\n",
    "#)\n",
    "\n",
    "#hyperparams = {\n",
    "#    \"optimization_approach\": \"brute_force\",\n",
    "#    \"num_samples\": 10,\n",
    "#    \"scm\": scm,\n",
    "#    \"constraint_handle\": constraints.point_constraint,\n",
    "#    \"sampler_handle\": samplers.sample_true_m0,\n",
    "#}\n",
    "#cfs = CausalRecourse(ml_model, hyperparams).get_counterfactuals(test_factual)\n",
    "\n",
    "display(cfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_from_causal(scm,values,cf_label, mapping_dict):\n",
    "    #TODO change everything hard coded\n",
    "    values['target']=cf_label\n",
    "    def _get_noise_string(node):\n",
    "        def _get_node_id(node):\n",
    "            return node[1:]\n",
    "        if not node[0] == \"x\":\n",
    "            raise ValueError\n",
    "        return \"u\" + _get_node_id(node)\n",
    "    exogenous_variables = np.concatenate(\n",
    "        [\n",
    "            np.array(values[mapping_dict[node]]).reshape(-1, 1)\n",
    "            for node in scm.get_topological_ordering(\"exogenous\")\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    exogenous_variables = pd.DataFrame(\n",
    "        exogenous_variables, columns=scm.get_topological_ordering(\"exogenous\")\n",
    "    )\n",
    "\n",
    "    endogenous_variables = exogenous_variables.copy()\n",
    "    endogenous_variables = endogenous_variables.rename(\n",
    "        columns=dict(\n",
    "            zip(\n",
    "                scm.get_topological_ordering(\"exogenous\"),\n",
    "                scm.get_topological_ordering(\"endogenous\"),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    # used later to make sure parents are populated when computing children\n",
    "    endogenous_variables.loc[:] = np.nan\n",
    "    for node in scm.get_topological_ordering(\"endogenous\"):\n",
    "        parents = scm.get_parents(node)\n",
    "        if endogenous_variables.loc[:, list(parents)].isnull().values.any():\n",
    "            raise ValueError(\n",
    "                \"parents in endogenous_variables should already be occupied\"\n",
    "            )\n",
    "        endogenous_variables[node] = scm.structural_equations_np[node](\n",
    "            exogenous_variables[_get_noise_string(node)],\n",
    "            *[endogenous_variables[p] for p in parents],\n",
    "        )\n",
    "    labels=endogenous_variables['x7'][0]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict={ \n",
    "    # Gender\n",
    "      'u1': 'x1',\n",
    "      # Age\n",
    "      'u2': 'x2',\n",
    "      # Education\n",
    "      'u3': 'x3',\n",
    "      # Loan amount\n",
    "      'u4':'x4',\n",
    "      # Loan duration\n",
    "      'u5': 'x5',\n",
    "      # Income\n",
    "      'u6': 'x6',\n",
    "      # Savings\n",
    "      'u7':'x7',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Histogram Features / true Positive / false Positive'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from carla.data import causal_model\n",
    "from carla.evaluation import remove_nans\n",
    "from carla.evaluation.api import Evaluation\n",
    "class Sematic(Evaluation):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ml_model, causal_graph):\n",
    "        self.ml_model= ml_model\n",
    "        self.causal_graph=causal_graph\n",
    "    def get_evaluation(self,factual: np.ndarray, counterfactual: np.ndarray, causal_model):\n",
    "        # generate data \n",
    "        cf_label=self.ml_model.predict(np.array(counterfactual.values).reshape(1,-1))\n",
    "        cf_label=np.argmax(cf_label)\n",
    "        causal_label=get_pred_from_causal(self.causal_graph,counterfactual,cf_label, mapping_dict)\n",
    "        print(cf_label)\n",
    "        if cf_label ==causal_label:\n",
    "            return 1 \n",
    "        else: \n",
    "            return 0\n",
    "\n",
    "class path_checker():\n",
    "    pass\n",
    "\n",
    "\n",
    "metric = Sematic(ml_model,scm)\n",
    "result=metric.get_evaluation(np.array([]),cfs.iloc[0],mapping_dict)\n",
    "''' \n",
    "Analysis\n",
    "Probitlity Distributions \n",
    "Histogram True Positive, False Positives \n",
    "'''\n",
    "'''\n",
    "Parts of counterfactuals actually change \n",
    "1hop and 2 hop relations \n",
    "'''\n",
    "'''Histogram Features / true Positive / false Positive'''\n",
    "# first initialize the benchmarking class by passing\n",
    "# black-box-model, recourse method, and factuals into it\n",
    "#benchmark = Benchmark(ml_model, recourse_method, factuals)\n",
    "\n",
    "# now you can decide if you want to run all measurements\n",
    "# or just specific ones.\n",
    "#evaluation_measures = [\n",
    "#    evaluation_catalog.YNN(benchmark.mlmodel, {\"y\": 5, \"cf_label\": 1}),\n",
    "#    evaluation_catalog.Distance(benchmark.mlmodel),\n",
    "#    evaluation_catalog.SuccessRate(),\n",
    "#    evaluation_catalog.Redundancy(benchmark.mlmodel, {\"cf_label\": 1}),\n",
    "#    evaluation_catalog.ConstraintViolation(benchmark.mlmodel),\n",
    "#    evaluation_catalog.AvgTime({\"time\": benchmark.timer}),\n",
    "#]\n",
    "\n",
    "# now run all implemented measurements and create a\n",
    "# DataFrame which consists of all results\n",
    "#results = benchmark.run_benchmark(evaluation_measures)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('CARLA-koH0yuP4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f55703f6f29bf5b3ae6360c8e9dbcc23e2b3226583ad9e6051e8921906faedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
