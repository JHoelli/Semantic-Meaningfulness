{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-7s4zdYsf/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "\n",
    "import Semantic_Maningfullness\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from carla.data.causal_model import CausalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import random\n",
    "\n",
    "#SEED Setting\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuzzy False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.822251</td>\n",
       "      <td>3.206103</td>\n",
       "      <td>1.394095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.125186</td>\n",
       "      <td>-0.267489</td>\n",
       "      <td>-0.065593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.388819</td>\n",
       "      <td>-2.420645</td>\n",
       "      <td>0.119093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.173873</td>\n",
       "      <td>-0.715379</td>\n",
       "      <td>-1.201855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.637307</td>\n",
       "      <td>1.071684</td>\n",
       "      <td>0.379442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971876</td>\n",
       "      <td>-0.067054</td>\n",
       "      <td>-1.317657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.792395</td>\n",
       "      <td>-2.272653</td>\n",
       "      <td>0.620624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.994518</td>\n",
       "      <td>-3.212899</td>\n",
       "      <td>-0.900646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.854051</td>\n",
       "      <td>3.213437</td>\n",
       "      <td>-0.361817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.368446</td>\n",
       "      <td>1.890917</td>\n",
       "      <td>-0.205989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label        x1        x2        x3\n",
       "0       1.0 -3.822251  3.206103  1.394095\n",
       "1       0.0 -0.125186 -0.267489 -0.065593\n",
       "2       0.0  1.388819 -2.420645  0.119093\n",
       "3       0.0 -0.173873 -0.715379 -1.201855\n",
       "4       1.0 -0.637307  1.071684  0.379442\n",
       "...     ...       ...       ...       ...\n",
       "9995    0.0  0.971876 -0.067054 -1.317657\n",
       "9996    1.0  1.792395 -2.272653  0.620624\n",
       "9997    0.0  1.994518 -3.212899 -0.900646\n",
       "9998    0.0 -2.854051  3.213437 -0.361817\n",
       "9999    0.0 -2.368446  1.890917 -0.205989\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# generate data\n",
    "scm = CausalModel(\"sanity-3-lin\")\n",
    "dataset = scm.generate_dataset(10000, False)\n",
    "\n",
    "# save data\n",
    "# dataset.df.to_csv('generate_dataset.csv')\n",
    "\n",
    "display(dataset.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Fraction of noisy labels \n",
    "\n",
    "def get_classification_from_scm(data, threshold=0.5): \n",
    "    #TODO Recheck Calculation \n",
    "    label=[]\n",
    "    for d in data.iterrows():\n",
    "        d=d[1]\n",
    "        d=d.drop('label')\n",
    "\n",
    "        # fix a hyperplane\n",
    "        w = np.ones((3, 1))\n",
    "        # get the average scale of (w^T)*X, this depends on the scale of the data\n",
    "        #print(d)\n",
    "        #print(d.shape)\n",
    "        scale = 2.5 / np.mean(np.abs(np.dot(d, w)))\n",
    "        predictions = 1 / (1 + np.exp(-scale * np.dot(d, w)))\n",
    "        #predictions=value[0]\n",
    "        uniform_rv = threshold\n",
    "        labels = int(uniform_rv < predictions)     \n",
    "        label.append(labels)\n",
    "\n",
    "    return label\n",
    "\n",
    "orig_lab= get_classification_from_scm(dataset.df)\n",
    "#print(orig_lab)\n",
    "#print(dataset.df['label'])\n",
    "noisyLabel=np.count_nonzero(dataset.df['label']-orig_lab)\n",
    "noisyLabel/len(dataset.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "#  Check if Original (non fuzzy) Calc and Output Model would result in identicall predicitons\n",
    "#THIS CELL Is Currently not excecuted\n",
    "data= dataset.df\n",
    "diff=0\n",
    "for d in data.iterrows():\n",
    "    d=d[1]\n",
    "    d=d.drop('label')\n",
    "    # ORIGINAL CALC\n",
    "    w = np.ones((3, 1))\n",
    "    scale = 2.5 / np.mean(np.abs(np.dot(d, w)))\n",
    "    predictions = 1 / (1 + np.exp(-scale * np.dot(d, w)))\n",
    "    # Calc in Output Model SCM \n",
    "    print(d.to_numpy())\n",
    "    print([round(d['x1'],8),round(d['x2'],8),round(d['x3'],8)])\n",
    "\n",
    "    #scale = \n",
    "    pred_scM= 1 / (1 + np.exp(-(2.5 / np.mean(np.abs(np.dot([round(d['x1'],8),round(d['x2'],8),round(d['x3'],8)], np.ones((3, 1)))))) * np.dot([round(d['x1'],8),round(d['x2'],8),round(d['x3'],8)], np.ones((3, 1)))))\n",
    "    #pred_scM= 1/ (1 + np.exp(- 2.5 / np.mean(np.abs(np.dot([round(d['x1'],8),round(d['x2'],8),round(d['x3'],8)], np.ones((3, 1))))))* np.dot([round(d['x1'],8),round(d['x2'],8),round(d['x3'],8)], np.ones((3, 1))))\n",
    "\n",
    "    print('1', predictions)\n",
    "    print('2', pred_scM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"90pt\" height=\"188pt\"\n viewBox=\"0.00 0.00 90.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 86,-184 86,4 -4,4\"/>\n<!-- x3 -->\n<g id=\"node1\" class=\"node\">\n<title>x3</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">x3</text>\n</g>\n<!-- x1 -->\n<g id=\"node2\" class=\"node\">\n<title>x1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">x1</text>\n</g>\n<!-- x1&#45;&gt;x3 -->\n<g id=\"edge2\" class=\"edge\">\n<title>x1&#45;&gt;x3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M23.75,-143.89C21.95,-133.54 19.91,-120.06 19,-108 17.8,-92.04 17.8,-87.96 19,-72 19.64,-63.52 20.84,-54.34 22.12,-46.04\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"25.58,-46.55 23.75,-36.11 18.68,-45.41 25.58,-46.55\"/>\n</g>\n<!-- x2 -->\n<g id=\"node3\" class=\"node\">\n<title>x2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"55\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"55\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">x2</text>\n</g>\n<!-- x1&#45;&gt;x2 -->\n<g id=\"edge1\" class=\"edge\">\n<title>x1&#45;&gt;x2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M33.64,-144.41C36.91,-136.22 40.94,-126.14 44.62,-116.95\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"47.95,-118.05 48.41,-107.47 41.45,-115.45 47.95,-118.05\"/>\n</g>\n<!-- x2&#45;&gt;x3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>x2&#45;&gt;x3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M48.36,-72.41C45.09,-64.22 41.06,-54.14 37.38,-44.95\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"40.55,-43.45 33.59,-35.47 34.05,-46.05 40.55,-43.45\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fad70a95690>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualize the model\n",
    "scm.cgm.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance on test set 0.5169333333333334, balance on test set 0.5152\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.0725 Acc: 0.9716\n",
      "\n",
      "test Loss: 0.0608 Acc: 0.9776\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0371 Acc: 0.9853\n",
      "\n",
      "test Loss: 0.0255 Acc: 0.9888\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0342 Acc: 0.9872\n",
      "\n",
      "test Loss: 0.0268 Acc: 0.9868\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0322 Acc: 0.9869\n",
      "\n",
      "test Loss: 0.0276 Acc: 0.9884\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0299 Acc: 0.9888\n",
      "\n",
      "test Loss: 0.0201 Acc: 0.9912\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0285 Acc: 0.9891\n",
      "\n",
      "test Loss: 0.0188 Acc: 0.9920\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0271 Acc: 0.9897\n",
      "\n",
      "test Loss: 0.0162 Acc: 0.9928\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0279 Acc: 0.9897\n",
      "\n",
      "test Loss: 0.0192 Acc: 0.9928\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0267 Acc: 0.9895\n",
      "\n",
      "test Loss: 0.0474 Acc: 0.9816\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0241 Acc: 0.9899\n",
      "\n",
      "test Loss: 0.0591 Acc: 0.9756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from carla.models.catalog import MLModelCatalog\n",
    "\n",
    "training_params = {\"lr\": 0.01, \"epochs\": 10, \"batch_size\": 16, \"hidden_size\": [18, 9, 3]}\n",
    "\n",
    "ml_model = MLModelCatalog(\n",
    "    dataset, model_type=\"ann\", load_online=False, backend=\"pytorch\"\n",
    ")\n",
    "ml_model.train(\n",
    "    learning_rate=training_params[\"lr\"],\n",
    "    epochs=training_params[\"epochs\"],\n",
    "    batch_size=training_params[\"batch_size\"],\n",
    "    hidden_size=training_params[\"hidden_size\"],\n",
    "    force_train=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label        x1        x2        x3\n",
      "0    0.0 -0.125186 -0.267489 -0.065593\n",
      "1    0.0  1.388819 -2.420645  0.119093\n",
      "2    0.0 -0.173873 -0.715379 -1.201855\n",
      "3    0.0 -2.087104  2.218720 -0.248939\n",
      "4    0.0 -1.895168  2.386755 -0.718443\n",
      "5    0.0  0.721627 -0.507613 -0.951930\n",
      "6    0.0 -1.589644 -0.152073 -0.688441\n",
      "7    0.0  1.564789 -2.419099 -1.798075\n",
      "8    0.0  0.787910 -1.019286 -0.083949\n",
      "9    0.0 -2.413814  1.743723 -0.176813\n"
     ]
    }
   ],
   "source": [
    "from carla.models.negative_instances import predict_negative_instances\n",
    "# get factuals\n",
    "factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "test_factual_with_labels = factuals.iloc[:10].reset_index(drop=True)\n",
    "test_factual=test_factual_with_labels.copy()\n",
    "\n",
    "print(test_factual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.85281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>-1.0184</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.1569</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.85281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.52572</td>\n",
       "      <td>2.1569</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.1569</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.1569</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.41998</td>\n",
       "      <td>-1.0184</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.85281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.85281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x1      x2       x3\n",
       "0  0.00000  0.0000  0.85281\n",
       "1  0.00000 -1.0184  0.00000\n",
       "2  0.00000  2.1569  0.00000\n",
       "3  0.00000  0.0000  0.85281\n",
       "4 -0.52572  2.1569  0.00000\n",
       "5  0.00000  2.1569  0.00000\n",
       "6  0.00000  2.1569  0.00000\n",
       "7  4.41998 -1.0184  0.00000\n",
       "8  0.00000  0.0000  0.85281\n",
       "9  0.00000  0.0000  0.85281"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x3</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.787217</td>\n",
       "      <td>-0.125186</td>\n",
       "      <td>-0.267489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.119093</td>\n",
       "      <td>1.388819</td>\n",
       "      <td>-3.439045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.201855</td>\n",
       "      <td>-0.173873</td>\n",
       "      <td>1.441521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.603871</td>\n",
       "      <td>-2.087104</td>\n",
       "      <td>2.218720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.718443</td>\n",
       "      <td>-2.420888</td>\n",
       "      <td>4.543655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.951930</td>\n",
       "      <td>0.721627</td>\n",
       "      <td>1.649287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.688441</td>\n",
       "      <td>-1.589644</td>\n",
       "      <td>2.004827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.798075</td>\n",
       "      <td>5.984769</td>\n",
       "      <td>-3.437499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.768861</td>\n",
       "      <td>0.787910</td>\n",
       "      <td>-1.019286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.675997</td>\n",
       "      <td>-2.413814</td>\n",
       "      <td>1.743723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x3        x1        x2\n",
       "0  0.787217 -0.125186 -0.267489\n",
       "1  0.119093  1.388819 -3.439045\n",
       "2 -1.201855 -0.173873  1.441521\n",
       "3  0.603871 -2.087104  2.218720\n",
       "4 -0.718443 -2.420888  4.543655\n",
       "5 -0.951930  0.721627  1.649287\n",
       "6 -0.688441 -1.589644  2.004827\n",
       "7 -1.798075  5.984769 -3.437499\n",
       "8  0.768861  0.787910 -1.019286\n",
       "9  0.675997 -2.413814  1.743723"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from carla.recourse_methods.catalog.causal_recourse import (\n",
    "    CausalRecourse,\n",
    "    constraints,\n",
    "    samplers,\n",
    ")\n",
    "hyperparams = {\n",
    "    \"optimization_approach\": \"brute_force\",\n",
    "    \"num_samples\": 10,\n",
    "    \"scm\": scm,\n",
    "    \"constraint_handle\": constraints.point_constraint,\n",
    "    \"sampler_handle\": samplers.sample_true_m0,\n",
    "}\n",
    "\n",
    "#TODO Does not return a classification ? \n",
    "# structural counterfactual (SCF)\n",
    "cfs = CausalRecourse(ml_model, hyperparams).get_counterfactuals(test_factual)\n",
    "\n",
    "output = cfs.reset_index(drop=True) - test_factual.loc[:,~test_factual.columns.isin(['label'])].reset_index(drop=True)\n",
    "display(output)\n",
    "display(cfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCM with Output Layer. \n",
    "#THIS IS ALREADY ADDED TO CARLA; ONLY HERE FOR COMPLETENESS / EASE OF UNDERSTANDING;  BELOW THE CARLA VERSION IS USED.\n",
    "from carla.data.load_scm.distributions import Bernoulli, MixtureOfGaussians, Normal,Uniform, Bernoulli, Gamma\n",
    "\n",
    "def sanity_3_lin_output():\n",
    "    structural_equations_np = {\n",
    "        \"x1\": lambda n_samples: n_samples,\n",
    "        \"x2\": lambda n_samples, x1: -x1 + n_samples,\n",
    "        \"x3\": lambda n_samples, x1, x2: 0.5 * (0.1 * x1 + 0.5 * x2) + n_samples,\n",
    "        \"x4\":lambda n_samples, x1, x2,x3: 1/ (1 + np.exp(- 2.5 / np.mean(np.abs(np.dot([x1,x2,x3], np.ones((3, 1))))))* np.dot([x1,x2,x3], np.ones((3, 1))))\n",
    "    }\n",
    "    structural_equations_ts = structural_equations_np\n",
    "    noises_distributions = {\n",
    "        \"u1\": MixtureOfGaussians([0.5, 0.5], [-2, +1], [1.5, 1]),\n",
    "        \"u2\": Normal(0, 1),\n",
    "        \"u3\": Normal(0, 1),\n",
    "        \"u4\": Normal(0, 1),\n",
    "    }\n",
    "    continuous = list(structural_equations_np.keys()) + list(\n",
    "        noises_distributions.keys()\n",
    "    )\n",
    "    categorical = []\n",
    "    immutables = []\n",
    "\n",
    "    return (\n",
    "        structural_equations_np,\n",
    "        structural_equations_ts,\n",
    "        noises_distributions,\n",
    "        continuous,\n",
    "        categorical,\n",
    "        immutables,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scm_output=CausalModel(\"sanity-3-lin-output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"122pt\" height=\"260pt\"\n viewBox=\"0.00 0.00 122.47 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-256 118.47,-256 118.47,4 -4,4\"/>\n<!-- x3 -->\n<g id=\"node1\" class=\"node\">\n<title>x3</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"41.47\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"41.47\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">x3</text>\n</g>\n<!-- x4 -->\n<g id=\"node2\" class=\"node\">\n<title>x4</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"41.47\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"41.47\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">x4</text>\n</g>\n<!-- x3&#45;&gt;x4 -->\n<g id=\"edge6\" class=\"edge\">\n<title>x3&#45;&gt;x4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M41.47,-71.7C41.47,-63.98 41.47,-54.71 41.47,-46.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"44.97,-46.1 41.47,-36.1 37.97,-46.1 44.97,-46.1\"/>\n</g>\n<!-- x1 -->\n<g id=\"node3\" class=\"node\">\n<title>x1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"32.47\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"32.47\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">x1</text>\n</g>\n<!-- x1&#45;&gt;x3 -->\n<g id=\"edge2\" class=\"edge\">\n<title>x1&#45;&gt;x3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M33.56,-215.87C35.09,-191.67 37.91,-147.21 39.74,-118.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"43.24,-118.39 40.38,-108.19 36.26,-117.95 43.24,-118.39\"/>\n</g>\n<!-- x1&#45;&gt;x4 -->\n<g id=\"edge3\" class=\"edge\">\n<title>x1&#45;&gt;x4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M24.86,-216.68C12.18,-187.23 -10.35,-123.47 5.47,-72 8.76,-61.31 15.01,-50.85 21.4,-42.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"24.36,-43.98 27.72,-33.93 18.83,-39.69 24.36,-43.98\"/>\n</g>\n<!-- x2 -->\n<g id=\"node4\" class=\"node\">\n<title>x2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"87.47\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"87.47\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">x2</text>\n</g>\n<!-- x1&#45;&gt;x2 -->\n<g id=\"edge1\" class=\"edge\">\n<title>x1&#45;&gt;x2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M44.41,-217.81C51.69,-208.55 61.14,-196.52 69.33,-186.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"72.14,-188.18 75.56,-178.16 66.63,-183.86 72.14,-188.18\"/>\n</g>\n<!-- x2&#45;&gt;x3 -->\n<g id=\"edge4\" class=\"edge\">\n<title>x2&#45;&gt;x3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M77.04,-145.12C71.27,-136.34 63.99,-125.26 57.52,-115.42\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"60.29,-113.26 51.87,-106.82 54.44,-117.1 60.29,-113.26\"/>\n</g>\n<!-- x2&#45;&gt;x4 -->\n<g id=\"edge5\" class=\"edge\">\n<title>x2&#45;&gt;x4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M87.95,-143.71C87.92,-125.35 86.27,-95.77 77.47,-72 73.6,-61.52 67.21,-51.09 60.89,-42.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"63.51,-39.97 54.69,-34.11 57.94,-44.2 63.51,-39.97\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fad505642d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualize the model\n",
    "scm_output.cgm.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cflabel from DL model [[0.9999919]]\n",
      "factuals_label from DL model [[0.00064077]]\n",
      "probability [0.92414182]\n",
      "cflabel from DL model [[1.1993149e-09]]\n",
      "factuals_label from DL model [[1.8307905e-05]]\n",
      "probability [0.07585818]\n",
      "cflabel from DL model [[0.3649371]]\n",
      "factuals_label from DL model [[6.4715344e-10]]\n",
      "probability [0.92414182]\n",
      "cflabel from DL model [[1.]]\n",
      "factuals_label from DL model [[0.0036917]]\n",
      "probability [0.92414182]\n",
      "cflabel from DL model [[1.]]\n",
      "factuals_label from DL model [[0.00157668]]\n",
      "probability [0.92414182]\n",
      "cflabel from DL model [[1.]]\n",
      "factuals_label from DL model [[5.5468878e-05]]\n",
      "probability [0.92414182]\n",
      "cflabel from DL model [[0.00156253]]\n",
      "factuals_label from DL model [[1.5163088e-11]]\n",
      "probability [0.07585818]\n",
      "cflabel from DL model [[0.9999999]]\n",
      "factuals_label from DL model [[4.9045243e-12]]\n",
      "probability [0.92414182]\n",
      "cflabel from DL model [[0.99999976]]\n",
      "factuals_label from DL model [[0.00230014]]\n",
      "probability [0.92414182]\n",
      "cflabel from DL model [[0.6345466]]\n",
      "factuals_label from DL model [[6.659596e-06]]\n",
      "probability [0.92414182]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from Semantic_Maningfullness import Sematic\n",
    "importlib.reload(Semantic_Maningfullness)\n",
    "\n",
    "mapping_dict={ \n",
    "      'u1': 'x1',\n",
    "      'u2': 'x2',\n",
    "    'u3': 'x3',\n",
    "      }\n",
    "results=[]\n",
    "i=0\n",
    "#scm_output= sanity_3_lin_output()\n",
    "\n",
    "test_factual = test_factual.loc[:,~test_factual.columns.isin(['label'])]\n",
    "\n",
    "for a in test_factual.index:\n",
    "\n",
    "    if str(cfs.iloc[i]['x1'])=='nan':\n",
    "        pass\n",
    "    else:\n",
    "        sem=Sematic(ml_model,scm_output,mapping_dict)\n",
    "        \n",
    "        res=sem.get_evaluation(test_factual.iloc[a],cfs.iloc[i])['semantic'][0]\n",
    "        results.append( res)\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability [0.07585818]\n",
      "probability [0.07585818]\n",
      "probability [0.07585818]\n",
      "probability [0.07585818]\n",
      "probability [0.07585818]\n",
      "probability [0.07585818]\n",
      "probability [0.07585818]\n",
      "probability [0.07585818]\n",
      "probability [0.07585818]\n",
      "probability [0.07585818]\n",
      "probability [0.92414182]\n",
      "probability [0.07585818]\n",
      "probability [0.92414182]\n",
      "probability [0.92414182]\n",
      "probability [0.92414182]\n",
      "probability [0.92414182]\n",
      "probability [0.07585818]\n",
      "probability [0.92414182]\n",
      "probability [0.92414182]\n",
      "probability [0.92414182]\n",
      "CF Consistency with DL Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.60      0.75        10\n",
      "\n",
      "    accuracy                           0.60        10\n",
      "   macro avg       0.50      0.30      0.37        10\n",
      "weighted avg       1.00      0.60      0.75        10\n",
      "\n",
      "CF Consistency with SCM Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.50      0.40      0.44        10\n",
      "weighted avg       1.00      0.80      0.89        10\n",
      "\n",
      "Factual Consistency with DL Model \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n",
      "Factual Consistency with SXM Model \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support,classification_report\n",
    "from Semantic_Maningfullness import get_pred_from_causal_v2\n",
    "# Model Accuracy for the above used CF and original test data \n",
    "original_test_x = test_factual_with_labels.drop(columns=['label'])\n",
    "original_test_y = test_factual_with_labels['label']\n",
    "original_test_y_pred= ml_model.predict(np.array(original_test_x.values).reshape(-1, original_test_x.values.shape[-1]))\n",
    "original_test_y_pred[np.argwhere(original_test_y_pred>0.5)]=1\n",
    "original_test_y_pred[np.argwhere(original_test_y_pred<=0.5)]=0\n",
    "original_test_scm_y_pred=[]\n",
    "for i,item in original_test_x.iterrows():\n",
    "    original_test_scm_y_pred.append(get_pred_from_causal_v2(scm_output, item, None, None, 0.5))\n",
    "\n",
    "# TODO  THIS IS CUTRRENTLY AN ASSUMPTION AS Recourse is only binary \n",
    "cf_test_x= cfs.iloc[test_factual.index]\n",
    "cf_test_y=np.zeros_like(original_test_y)\n",
    "cf_test_y_pred=  ml_model.predict(np.array(cf_test_x.values).reshape(-1, cf_test_x.values.shape[-1]))\n",
    "cf_test_y_pred[np.argwhere(cf_test_y_pred>0.5)]=1\n",
    "cf_test_y_pred[np.argwhere(cf_test_y_pred<=0.5)]=0\n",
    "for i, x in enumerate(original_test_y):\n",
    "    if x== 0:\n",
    "        cf_test_y[i]=1\n",
    "\n",
    "cf_test_scm_y_pred=[]\n",
    "for i,item in cf_test_x.iterrows():\n",
    "    cf_test_scm_y_pred.append(get_pred_from_causal_v2(scm_output, item, None, None, 0.5))\n",
    "\n",
    "\n",
    "'''CF Consistency with DL Model'''\n",
    "print('CF Consistency with DL Model')\n",
    "cf_metrics= classification_report(cf_test_y,cf_test_y_pred.reshape(-1))\n",
    "print(cf_metrics)\n",
    "'''CF Consistency with SCM Model'''\n",
    "print('CF Consistency with SCM Model')\n",
    "cf_scm_metrics= classification_report(cf_test_y,cf_test_scm_y_pred)\n",
    "print(cf_scm_metrics)\n",
    "'''Factual Consistency with DL Model '''\n",
    "print('Factual Consistency with DL Model ')\n",
    "factual_metrics= classification_report(original_test_y ,original_test_y_pred.reshape(-1))\n",
    "print(factual_metrics)\n",
    "'''Factual Consistency with SXM Model '''\n",
    "print('Factual Consistency with SXM Model ')\n",
    "factual_scm_metrics= classification_report(original_test_y ,original_test_scm_y_pred)\n",
    "print(factual_scm_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic results 0.9 +/- 0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "# Averaging of the reults\n",
    "mean= np.mean(results)\n",
    "std= np.std(results)\n",
    "print(f'Semantic results {mean} +/- {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([2]),)\n",
      "         x3        x1        x2\n",
      "2 -1.201855 -0.173873  1.441521\n"
     ]
    }
   ],
   "source": [
    "#TODO This is currently not workin \n",
    "# Building Probability Distribution of the output divided into complient/ not complient\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "# Data Distribution\n",
    "id_comp= np.where(np.array(results)==1)\n",
    "id_not_comp=np.where(np.array(results)==0)\n",
    "print(id_not_comp)\n",
    "if len(id_comp[0])==0:\n",
    "    cfs_complient=[]\n",
    "    cfs_complient_predict=[]\n",
    "    \n",
    "else:\n",
    "    cfs_complient=cfs.iloc[id_comp[0]]\n",
    "    cfs_complient_predict=np.max(ml_model.predict(np.array(cfs_complient.values).reshape(-1,cfs_complient.values.shape[-1])),axis=1)\n",
    "cfs_not_complient=cfs.iloc[id_not_comp[0]]\n",
    "\n",
    "print(cfs_not_complient)\n",
    "\n",
    "\n",
    "# cfs_not_complient_predict=np.max(ml_model.predict(np.array(cfs_not_complient).reshape(-1,7)),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfs_not_complient_predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_89012/4146009255.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcfs_complient_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcfs_complient_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcfs_not_complient_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcfs_not_complient_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcfs_complient_predict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfs_complient_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcfs_not_complient_predict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfs_not_complient_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cfs_not_complient_predict' is not defined"
     ]
    }
   ],
   "source": [
    "#BoxPlot\n",
    "import  numpy\n",
    "from math import nan, isnan\n",
    "cfs_complient_predict = [x for x in cfs_complient_predict if isnan(x) == False]\n",
    "cfs_not_complient_predict = [x for x in cfs_not_complient_predict if isnan(x) == False]\n",
    "cfs_complient_predict=np.array(cfs_complient_predict).reshape(-1)\n",
    "cfs_not_complient_predict=np.array(cfs_not_complient_predict).reshape(-1)\n",
    "\n",
    "print(cfs_not_complient_predict)\n",
    "data = [cfs_complient_predict,cfs_not_complient_predict]\n",
    "\n",
    "fig7, ax7 = plt.subplots()\n",
    "ax7.set_title('Complient vs Not Complient')\n",
    "ax7.boxplot(data)\n",
    "\n",
    "#plt.ylim((0.99,1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('CARLA-7s4zdYsf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05951db0b7a8fb6113eda4ec48ea77d75ed33c5045908c39c7a5079655347ffc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
