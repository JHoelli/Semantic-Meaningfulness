{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n"
     ]
    }
   ],
   "source": [
    "from carla import Benchmark\n",
    "from IPython.display import display\n",
    "import carla.evaluation.catalog as evaluation_catalog\n",
    "from carla.data.catalog import OnlineCatalog\n",
    "from carla.models.catalog import MLModelCatalog\n",
    "from carla.models.negative_instances import predict_negative_instances\n",
    "import carla.recourse_methods.catalog as recourse_catalog\n",
    "import shap \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from carla.data.causal_model import CausalModel\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from carla.data.catalog import CsvCatalog\n",
    "import numpy as np \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scm = CausalModel(\"credit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"232pt\" height=\"260pt\"\n viewBox=\"0.00 0.00 232.21 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-256 228.2076,-256 228.2076,4 -4,4\"/>\n<!-- x1 -->\n<g id=\"node1\" class=\"node\">\n<title>x1</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"77.2258\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"77.2258\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x1</text>\n</g>\n<!-- x3 -->\n<g id=\"node4\" class=\"node\">\n<title>x3</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"150.2258\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"150.2258\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x3</text>\n</g>\n<!-- x1&#45;&gt;x3 -->\n<g id=\"edge1\" class=\"edge\">\n<title>x1&#45;&gt;x3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M92.3514,-219.0816C102.5603,-209.0125 116.2136,-195.5463 127.695,-184.2221\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"130.2064,-186.6611 134.8683,-177.147 125.2909,-181.6773 130.2064,-186.6611\"/>\n</g>\n<!-- x4 -->\n<g id=\"node5\" class=\"node\">\n<title>x4</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"40.2258\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"40.2258\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x4</text>\n</g>\n<!-- x1&#45;&gt;x4 -->\n<g id=\"edge2\" class=\"edge\">\n<title>x1&#45;&gt;x4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M68.4573,-216.937C64.0978,-208.4537 58.7305,-198.0092 53.8505,-188.513\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"56.8721,-186.7352 49.1883,-179.4407 50.6461,-189.9348 56.8721,-186.7352\"/>\n</g>\n<!-- x6 -->\n<g id=\"node6\" class=\"node\">\n<title>x6</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"150.2258\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"150.2258\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x6</text>\n</g>\n<!-- x1&#45;&gt;x6 -->\n<g id=\"edge4\" class=\"edge\">\n<title>x1&#45;&gt;x6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M83.3278,-216.2804C89.9675,-197.7834 101.3692,-168.1603 114.2258,-144 119.4659,-134.1528 126.0369,-123.846 132.1259,-114.9077\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"135.1432,-116.6995 137.9869,-106.4934 129.3993,-112.6985 135.1432,-116.6995\"/>\n</g>\n<!-- x5 -->\n<g id=\"node7\" class=\"node\">\n<title>x5</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"40.2258\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"40.2258\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x5</text>\n</g>\n<!-- x1&#45;&gt;x5 -->\n<g id=\"edge3\" class=\"edge\">\n<title>x1&#45;&gt;x5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.4666,-224.2216C37.1793,-215.4263 14.6577,-200.6926 4.2258,-180 -6.7613,-158.2061 6.2549,-132.22 19.6037,-113.7866\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"22.5467,-115.7015 25.8769,-105.6436 17.0014,-111.4295 22.5467,-115.7015\"/>\n</g>\n<!-- x7 -->\n<g id=\"node2\" class=\"node\">\n<title>x7</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"150.2258\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"150.2258\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x7</text>\n</g>\n<!-- x2 -->\n<g id=\"node3\" class=\"node\">\n<title>x2</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"168.2258\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"168.2258\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x2</text>\n</g>\n<!-- x2&#45;&gt;x3 -->\n<g id=\"edge5\" class=\"edge\">\n<title>x2&#45;&gt;x3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M163.7763,-216.2022C161.7859,-208.2406 159.3925,-198.6671 157.1747,-189.7957\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"160.5073,-188.6951 154.6864,-179.8425 153.7163,-190.3929 160.5073,-188.6951\"/>\n</g>\n<!-- x2&#45;&gt;x4 -->\n<g id=\"edge6\" class=\"edge\">\n<title>x2&#45;&gt;x4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M147.3755,-222.2717C126.3624,-210.4519 93.7331,-192.0979 70.0001,-178.7481\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"71.4988,-175.5754 61.0671,-173.7233 68.067,-181.6764 71.4988,-175.5754\"/>\n</g>\n<!-- x2&#45;&gt;x6 -->\n<g id=\"edge8\" class=\"edge\">\n<title>x2&#45;&gt;x6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M186.553,-220.6978C198.3449,-210.9363 212.6513,-196.5364 219.2258,-180 225.137,-165.132 226.2338,-158.3836 219.2258,-144 211.2253,-127.5796 195.5493,-114.6826 181.1584,-105.6165\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"182.8345,-102.5415 172.4443,-100.4693 179.2744,-108.5686 182.8345,-102.5415\"/>\n</g>\n<!-- x2&#45;&gt;x5 -->\n<g id=\"edge7\" class=\"edge\">\n<title>x2&#45;&gt;x5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M178.5672,-217.1947C188.9909,-197.863 201.5233,-165.9684 186.2258,-144 173.2895,-125.4226 114.7594,-108.034 75.8497,-98.2341\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"76.482,-94.7853 65.9352,-95.7933 74.8086,-101.5824 76.482,-94.7853\"/>\n</g>\n<!-- x3&#45;&gt;x6 -->\n<g id=\"edge9\" class=\"edge\">\n<title>x3&#45;&gt;x6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M150.2258,-143.8314C150.2258,-136.131 150.2258,-126.9743 150.2258,-118.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"153.7259,-118.4132 150.2258,-108.4133 146.7259,-118.4133 153.7259,-118.4132\"/>\n</g>\n<!-- x4&#45;&gt;x5 -->\n<g id=\"edge10\" class=\"edge\">\n<title>x4&#45;&gt;x5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M40.2258,-143.8314C40.2258,-136.131 40.2258,-126.9743 40.2258,-118.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"43.7259,-118.4132 40.2258,-108.4133 36.7259,-118.4133 43.7259,-118.4132\"/>\n</g>\n<!-- x6&#45;&gt;x7 -->\n<g id=\"edge11\" class=\"edge\">\n<title>x6&#45;&gt;x7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M150.2258,-71.8314C150.2258,-64.131 150.2258,-54.9743 150.2258,-46.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"153.7259,-46.4132 150.2258,-36.4133 146.7259,-46.4133 153.7259,-46.4132\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f77939aa710>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scm.cgm.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x6</th>\n",
       "      <th>x5</th>\n",
       "      <th>x7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.374302</td>\n",
       "      <td>0.028619</td>\n",
       "      <td>-1.129844</td>\n",
       "      <td>-2.744300</td>\n",
       "      <td>-0.625192</td>\n",
       "      <td>2.084647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.210871</td>\n",
       "      <td>-0.192705</td>\n",
       "      <td>1.904234</td>\n",
       "      <td>4.607893</td>\n",
       "      <td>3.063371</td>\n",
       "      <td>2.285584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.373330</td>\n",
       "      <td>-0.233179</td>\n",
       "      <td>-0.697765</td>\n",
       "      <td>-0.103181</td>\n",
       "      <td>-0.879360</td>\n",
       "      <td>-2.617862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.385995</td>\n",
       "      <td>-0.164042</td>\n",
       "      <td>0.581720</td>\n",
       "      <td>-1.169078</td>\n",
       "      <td>-0.305056</td>\n",
       "      <td>-0.719612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.477485</td>\n",
       "      <td>-0.002458</td>\n",
       "      <td>4.699787</td>\n",
       "      <td>1.641210</td>\n",
       "      <td>5.695354</td>\n",
       "      <td>-0.277160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.316467</td>\n",
       "      <td>-0.169398</td>\n",
       "      <td>0.106817</td>\n",
       "      <td>-3.640827</td>\n",
       "      <td>-2.903189</td>\n",
       "      <td>-3.661007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.346044</td>\n",
       "      <td>-0.092425</td>\n",
       "      <td>0.204575</td>\n",
       "      <td>-1.530660</td>\n",
       "      <td>-1.131548</td>\n",
       "      <td>-5.526926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-17.451622</td>\n",
       "      <td>-0.059597</td>\n",
       "      <td>-4.869311</td>\n",
       "      <td>-0.413393</td>\n",
       "      <td>-6.467327</td>\n",
       "      <td>-3.452923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.465504</td>\n",
       "      <td>-0.161200</td>\n",
       "      <td>2.130428</td>\n",
       "      <td>-1.651074</td>\n",
       "      <td>-2.197170</td>\n",
       "      <td>5.218185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.085406</td>\n",
       "      <td>-0.183777</td>\n",
       "      <td>-3.151507</td>\n",
       "      <td>-0.304705</td>\n",
       "      <td>-4.785071</td>\n",
       "      <td>-11.569094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label   x1         x2        x3        x4        x6        x5         x7\n",
       "0      0.0  1.0  -5.374302  0.028619 -1.129844 -2.744300 -0.625192   2.084647\n",
       "1      0.0  1.0  -5.210871 -0.192705  1.904234  4.607893  3.063371   2.285584\n",
       "2      1.0  0.0   2.373330 -0.233179 -0.697765 -0.103181 -0.879360  -2.617862\n",
       "3      0.0  0.0 -13.385995 -0.164042  0.581720 -1.169078 -0.305056  -0.719612\n",
       "4      1.0  1.0   3.477485 -0.002458  4.699787  1.641210  5.695354  -0.277160\n",
       "..     ...  ...        ...       ...       ...       ...       ...        ...\n",
       "995    0.0  1.0 -15.316467 -0.169398  0.106817 -3.640827 -2.903189  -3.661007\n",
       "996    1.0  0.0   2.346044 -0.092425  0.204575 -1.530660 -1.131548  -5.526926\n",
       "997    0.0  1.0 -17.451622 -0.059597 -4.869311 -0.413393 -6.467327  -3.452923\n",
       "998    1.0  0.0  -2.465504 -0.161200  2.130428 -1.651074 -2.197170   5.218185\n",
       "999    1.0  0.0  22.085406 -0.183777 -3.151507 -0.304705 -4.785071 -11.569094\n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dataset = scm.generate_dataset(1000)\n",
    "dataset.df.to_csv('credit_synthetic.csv',index=False)\n",
    "display(dataset.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Build Dataset for Wachter'''\n",
    "import pandas as pd\n",
    "# Load Data \n",
    "dataframe = pd.read_csv('./credit_synthetic.csv')\n",
    "continuous = dataframe.drop(columns=['label']).columns\n",
    "\n",
    "dataset = CsvCatalog(file_path=\"credit_synthetic.csv\",\n",
    "                     continuous=continuous,\n",
    "                     categorical=[],\n",
    "                     immutables=[],\n",
    "                     target='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance on test set 0.49066666666666664, balance on test set 0.492\n",
      "Epoch 0/2\n",
      "----------\n",
      "train Loss: 0.5947 Acc: 0.6680\n",
      "\n",
      "test Loss: 0.5683 Acc: 0.7240\n",
      "\n",
      "Epoch 1/2\n",
      "----------\n",
      "train Loss: 0.4310 Acc: 0.8013\n",
      "\n",
      "test Loss: 0.4949 Acc: 0.7520\n",
      "\n",
      "Epoch 2/2\n",
      "----------\n",
      "train Loss: 0.3707 Acc: 0.8240\n",
      "\n",
      "test Loss: 0.4141 Acc: 0.8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model \n",
    "\n",
    "training_params = {\"lr\": 0.01, \"epochs\": 3, \"batch_size\": 16, \"hidden_size\": [18, 9, 2]}\n",
    "\n",
    "ml_model = MLModelCatalog(\n",
    "    dataset, model_type=\"ann\", load_online=False, backend=\"pytorch\"\n",
    ")\n",
    "ml_model.train(\n",
    "    learning_rate=training_params[\"lr\"],\n",
    "    epochs=training_params[\"epochs\"],\n",
    "    batch_size=training_params[\"batch_size\"],\n",
    "    hidden_size=training_params[\"hidden_size\"],\n",
    "    force_train=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x6</th>\n",
       "      <th>x5</th>\n",
       "      <th>x7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.264942</td>\n",
       "      <td>0.573268</td>\n",
       "      <td>0.633194</td>\n",
       "      <td>0.297634</td>\n",
       "      <td>0.515974</td>\n",
       "      <td>0.537355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152185</td>\n",
       "      <td>0.302672</td>\n",
       "      <td>0.701577</td>\n",
       "      <td>0.392132</td>\n",
       "      <td>0.528429</td>\n",
       "      <td>0.466921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344386</td>\n",
       "      <td>0.501847</td>\n",
       "      <td>0.783556</td>\n",
       "      <td>0.292421</td>\n",
       "      <td>0.674749</td>\n",
       "      <td>0.241932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.304560</td>\n",
       "      <td>0.387983</td>\n",
       "      <td>0.687191</td>\n",
       "      <td>0.549831</td>\n",
       "      <td>0.360148</td>\n",
       "      <td>0.410770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123327</td>\n",
       "      <td>0.147640</td>\n",
       "      <td>0.536624</td>\n",
       "      <td>0.317858</td>\n",
       "      <td>0.315270</td>\n",
       "      <td>0.270750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290445</td>\n",
       "      <td>0.461948</td>\n",
       "      <td>0.681572</td>\n",
       "      <td>0.307808</td>\n",
       "      <td>0.555568</td>\n",
       "      <td>0.385659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.282091</td>\n",
       "      <td>0.363074</td>\n",
       "      <td>0.762456</td>\n",
       "      <td>0.583355</td>\n",
       "      <td>0.426068</td>\n",
       "      <td>0.575325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259855</td>\n",
       "      <td>0.050772</td>\n",
       "      <td>0.726107</td>\n",
       "      <td>0.485632</td>\n",
       "      <td>0.380544</td>\n",
       "      <td>0.521276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297998</td>\n",
       "      <td>0.530258</td>\n",
       "      <td>0.609771</td>\n",
       "      <td>0.286805</td>\n",
       "      <td>0.440576</td>\n",
       "      <td>0.122729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182153</td>\n",
       "      <td>0.350120</td>\n",
       "      <td>0.643757</td>\n",
       "      <td>0.255335</td>\n",
       "      <td>0.413095</td>\n",
       "      <td>0.379274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.058129</td>\n",
       "      <td>0.407141</td>\n",
       "      <td>0.668144</td>\n",
       "      <td>0.263259</td>\n",
       "      <td>0.651034</td>\n",
       "      <td>0.357262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138372</td>\n",
       "      <td>0.135265</td>\n",
       "      <td>0.573675</td>\n",
       "      <td>0.335412</td>\n",
       "      <td>0.204371</td>\n",
       "      <td>0.311105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.288966</td>\n",
       "      <td>0.535044</td>\n",
       "      <td>0.789315</td>\n",
       "      <td>0.448771</td>\n",
       "      <td>0.504995</td>\n",
       "      <td>0.305608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.188663</td>\n",
       "      <td>0.237363</td>\n",
       "      <td>0.589657</td>\n",
       "      <td>0.636194</td>\n",
       "      <td>0.574546</td>\n",
       "      <td>0.582603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.181443</td>\n",
       "      <td>0.291319</td>\n",
       "      <td>0.653352</td>\n",
       "      <td>0.480548</td>\n",
       "      <td>0.580909</td>\n",
       "      <td>0.361079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.197714</td>\n",
       "      <td>0.560817</td>\n",
       "      <td>0.740748</td>\n",
       "      <td>0.377053</td>\n",
       "      <td>0.785134</td>\n",
       "      <td>0.531661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176893</td>\n",
       "      <td>0.478353</td>\n",
       "      <td>0.478226</td>\n",
       "      <td>0.457641</td>\n",
       "      <td>0.282914</td>\n",
       "      <td>0.434422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121052</td>\n",
       "      <td>0.272223</td>\n",
       "      <td>0.626033</td>\n",
       "      <td>0.578965</td>\n",
       "      <td>0.419437</td>\n",
       "      <td>0.330256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233737</td>\n",
       "      <td>0.398374</td>\n",
       "      <td>0.630713</td>\n",
       "      <td>0.537307</td>\n",
       "      <td>0.365352</td>\n",
       "      <td>0.351766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.168590</td>\n",
       "      <td>0.498466</td>\n",
       "      <td>0.703907</td>\n",
       "      <td>0.555174</td>\n",
       "      <td>0.596496</td>\n",
       "      <td>0.395110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.500887</td>\n",
       "      <td>0.679698</td>\n",
       "      <td>0.355370</td>\n",
       "      <td>0.542986</td>\n",
       "      <td>0.510749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092611</td>\n",
       "      <td>0.265758</td>\n",
       "      <td>0.365225</td>\n",
       "      <td>0.369256</td>\n",
       "      <td>0.184923</td>\n",
       "      <td>0.240820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.266572</td>\n",
       "      <td>0.613197</td>\n",
       "      <td>0.532766</td>\n",
       "      <td>0.473966</td>\n",
       "      <td>0.479905</td>\n",
       "      <td>0.435310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271220</td>\n",
       "      <td>0.530202</td>\n",
       "      <td>0.651688</td>\n",
       "      <td>0.502989</td>\n",
       "      <td>0.357434</td>\n",
       "      <td>0.375067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123725</td>\n",
       "      <td>0.222638</td>\n",
       "      <td>0.633942</td>\n",
       "      <td>0.292423</td>\n",
       "      <td>0.429281</td>\n",
       "      <td>0.456942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label   x1        x2        x3        x4        x6        x5        x7\n",
       "0     0.0  1.0  0.264942  0.573268  0.633194  0.297634  0.515974  0.537355\n",
       "3     0.0  0.0  0.152185  0.302672  0.701577  0.392132  0.528429  0.466921\n",
       "6     1.0  0.0  0.344386  0.501847  0.783556  0.292421  0.674749  0.241932\n",
       "10    0.0  1.0  0.304560  0.387983  0.687191  0.549831  0.360148  0.410770\n",
       "11    0.0  0.0  0.123327  0.147640  0.536624  0.317858  0.315270  0.270750\n",
       "12    1.0  0.0  0.290445  0.461948  0.681572  0.307808  0.555568  0.385659\n",
       "13    0.0  0.0  0.282091  0.363074  0.762456  0.583355  0.426068  0.575325\n",
       "15    0.0  0.0  0.259855  0.050772  0.726107  0.485632  0.380544  0.521276\n",
       "16    0.0  0.0  0.297998  0.530258  0.609771  0.286805  0.440576  0.122729\n",
       "19    0.0  0.0  0.182153  0.350120  0.643757  0.255335  0.413095  0.379274\n",
       "24    0.0  1.0  0.058129  0.407141  0.668144  0.263259  0.651034  0.357262\n",
       "25    0.0  0.0  0.138372  0.135265  0.573675  0.335412  0.204371  0.311105\n",
       "26    0.0  1.0  0.288966  0.535044  0.789315  0.448771  0.504995  0.305608\n",
       "27    0.0  1.0  0.188663  0.237363  0.589657  0.636194  0.574546  0.582603\n",
       "28    0.0  1.0  0.181443  0.291319  0.653352  0.480548  0.580909  0.361079\n",
       "32    1.0  1.0  0.197714  0.560817  0.740748  0.377053  0.785134  0.531661\n",
       "35    0.0  0.0  0.176893  0.478353  0.478226  0.457641  0.282914  0.434422\n",
       "36    0.0  1.0  0.121052  0.272223  0.626033  0.578965  0.419437  0.330256\n",
       "38    0.0  0.0  0.233737  0.398374  0.630713  0.537307  0.365352  0.351766\n",
       "40    0.0  1.0  0.168590  0.498466  0.703907  0.555174  0.596496  0.395110\n",
       "41    0.0  0.0  0.155104  0.500887  0.679698  0.355370  0.542986  0.510749\n",
       "42    0.0  0.0  0.092611  0.265758  0.365225  0.369256  0.184923  0.240820\n",
       "44    0.0  1.0  0.266572  0.613197  0.532766  0.473966  0.479905  0.435310\n",
       "46    0.0  1.0  0.271220  0.530202  0.651688  0.502989  0.357434  0.375067\n",
       "47    0.0  0.0  0.123725  0.222638  0.633942  0.292423  0.429281  0.456942"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from carla.models.negative_instances import predict_negative_instances\n",
    "import carla.recourse_methods.catalog as recourse_catalog\n",
    "\n",
    "factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "test_factual = factuals.iloc[:25]\n",
    "\n",
    "display(test_factual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {\"loss_type\": \"BCE\"}\n",
    "\n",
    "recourse_method = recourse_catalog.Wachter(ml_model, hyperparams)\n",
    "cfs = recourse_method.get_counterfactuals(test_factual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_from_causal(scm,values,cf_label, mapping_dict):\n",
    "    #TODO change everything hard coded\n",
    "    values['target']=cf_label\n",
    "    #print(values)\n",
    "    def _get_noise_string(node):\n",
    "        def _get_node_id(node):\n",
    "            return node[1:]\n",
    "        if not node[0] == \"x\":\n",
    "            raise ValueError\n",
    "        return \"u\" + _get_node_id(node)\n",
    "    exogenous_variables = np.concatenate(\n",
    "        [\n",
    "            #np.array(scm.noise_distributions[node].sample(1)).reshape(-1, 1)\n",
    "            np.array(values[mapping_dict[node]]).reshape(-1, 1)\n",
    "            for node in scm.get_topological_ordering(\"exogenous\")\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    exogenous_variables = pd.DataFrame(\n",
    "        exogenous_variables, columns=scm.get_topological_ordering(\"exogenous\")\n",
    "    )\n",
    "\n",
    "    endogenous_variables =exogenous_variables.copy() # np.array(values[mapping_dict[node]]).reshape(-1, 1)\n",
    "    endogenous_variables = endogenous_variables.rename(\n",
    "        columns=dict(\n",
    "            zip(\n",
    "                scm.get_topological_ordering(\"exogenous\"),\n",
    "                scm.get_topological_ordering(\"endogenous\"),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    # used later to make sure parents are populated when computing children\n",
    "    endogenous_variables.loc[:] = np.nan\n",
    "    for node in scm.get_topological_ordering(\"endogenous\"):\n",
    "        #print(node)\n",
    "        parents = scm.get_parents(node)\n",
    "        if endogenous_variables.loc[:, list(parents)].isnull().values.any():\n",
    "            raise ValueError(\n",
    "                \"parents in endogenous_variables should already be occupied\"\n",
    "            )\n",
    "        #print(_get_noise_string(node))\n",
    "        endogenous_variables[node] = scm.structural_equations_np[node](\n",
    "            exogenous_variables[_get_noise_string(node)],\n",
    "            *[endogenous_variables[p] for p in parents],\n",
    "\n",
    "\n",
    "        )\n",
    "    # fix a hyperplane\n",
    "    w = np.ones((endogenous_variables.shape[1], 1))\n",
    "    # get the average scale of (w^T)*X, this depends on the scale of the data\n",
    "    scale = 2.5 / np.mean(np.abs(np.dot(endogenous_variables, w)))\n",
    "    predictions = 1 / (1 + np.exp(-scale * np.dot(endogenous_variables, w)))\n",
    "\n",
    "    #if not 0.20 < np.std(predictions) < 0.42:\n",
    "    #    raise ValueError(f\"std of labels is strange: {np.std(predictions)}\")\n",
    "\n",
    "    # sample labels from class probabilities in predictions\n",
    "    uniform_rv = np.random.rand(endogenous_variables.shape[0], 1)\n",
    "    labels = int(uniform_rv < predictions)\n",
    "    #labels = pd.DataFrame(data=labels, columns={\"label\"})\n",
    "    #print('labels', labels)\n",
    "    #labels=endogenous_variables['x7'][0]\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict={ \n",
    "    # Gender\n",
    "      'u1': 'x1',\n",
    "      # Age\n",
    "      'u2': 'x2',\n",
    "      # Education\n",
    "      'u3': 'x3',\n",
    "      # Loan amount\n",
    "      'u4':'x4',\n",
    "      # Loan duration\n",
    "      'u5': 'x5',\n",
    "      # Income\n",
    "      'u6': 'x6',\n",
    "      # Savings\n",
    "      'u7':'x7',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cflabel [[0.50477284]]\n",
      "1\n",
      "labels 0\n",
      "Causal 0\n",
      "cflabel [[0.5020996]]\n",
      "1\n",
      "labels 0\n",
      "Causal 0\n",
      "cflabel [[0.5683797]]\n",
      "1\n",
      "labels 0\n",
      "Causal 0\n",
      "cflabel [[0.5091228]]\n",
      "1\n",
      "labels 0\n",
      "Causal 0\n",
      "cflabel [[0.55117023]]\n",
      "1\n",
      "labels 0\n",
      "Causal 0\n",
      "cflabel [[0.55982524]]\n",
      "1\n",
      "labels 0\n",
      "Causal 0\n",
      "cflabel [[0.54302466]]\n",
      "1\n",
      "labels 0\n",
      "Causal 0\n",
      "cflabel [[0.5551793]]\n",
      "1\n",
      "labels 0\n",
      "Causal 0\n",
      "cflabel [[0.5474928]]\n",
      "1\n",
      "labels 1\n",
      "Causal 1\n",
      "cflabel [[0.5479639]]\n",
      "1\n",
      "labels 0\n",
      "Causal 0\n",
      "cflabel [[0.5371695]]\n",
      "1\n",
      "labels 1\n",
      "Causal 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cmath import nan\n",
    "from telnetlib import SE\n",
    "from carla.data import causal_model\n",
    "from carla.evaluation import remove_nans\n",
    "from carla.evaluation.api import Evaluation\n",
    "class Sematic(Evaluation):\n",
    "    \"\"\"\n",
    "    Semnatic Evaluation Metric.\n",
    "    Attributes: \n",
    "        ml_model: Machine Learning Model\n",
    "        causal_graph: ground truth causal graph\n",
    "        mapping_dict: name mapping\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ml_model, causal_graph,mapping_dict):\n",
    "        self.ml_model= ml_model\n",
    "        self.causal_graph=causal_graph\n",
    "        self.mapping_dict=mapping_dict\n",
    "    def get_evaluation(self,factuals: np.ndarray, counterfactuals: np.ndarray):\n",
    "        # generate data \n",
    "        cf_label=self.ml_model.predict(np.array(counterfactuals.values).reshape(-1,counterfactuals.values.shape[-1]))\n",
    "        print('cflabel', cf_label)\n",
    "        if cf_label[0][0] > 0.5: \n",
    "            cf_label=1\n",
    "        else:\n",
    "            cf_label=0\n",
    "        print(cf_label)\n",
    "        #cf_label=np.argmax(cf_label)\n",
    "        causal_label=get_pred_from_causal(self.causal_graph,counterfactuals,cf_label, self.mapping_dict)\n",
    "        #print(cf_label)\n",
    "        print('Causal',causal_label)\n",
    "        if cf_label ==causal_label:\n",
    "            return pd.DataFrame([[1]], columns=[\"semantic\"])\n",
    "        else: \n",
    "            return pd.DataFrame([[0]], columns=[\"semantic\"])\n",
    "'''Histogram Features / true Positive / false Positive'''\n",
    "# first initialize the benchmarking class by passing\n",
    "# black-box-model, recourse method, and factuals into it#\n",
    "results=[]\n",
    "i=0\n",
    "#print(factuals.iloc[:20])\n",
    "for a in test_factual.index:\n",
    "    #print(test_factual.index)\n",
    "\n",
    "    if str(cfs.iloc[i]['x1'])=='nan':\n",
    "        pass\n",
    "    else:\n",
    "        sem= Sematic(ml_model,scm,mapping_dict)\n",
    "        try:\n",
    "            res=sem.get_evaluation(test_factual.iloc[a],cfs.iloc[i])['semantic'][0]\n",
    "            results.append( res)\n",
    "        except: \n",
    "            pass\n",
    "    i=i+1\n",
    "\n",
    "\n",
    "#benchmark = Benchmark(ml_model, recourse_method, factuals[:20])\n",
    "\n",
    "# now you can decide if you want to run all measurements\n",
    "# or just specific ones.\n",
    "#evaluation_measures = [\n",
    "#    Sematic(ml_model,scm,mapping_dict)\n",
    "#]\n",
    "\n",
    "#results = benchmark.run_benchmark(evaluation_measures)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic results 0.18181818181818182 +/- 0.385694607919935\n"
     ]
    }
   ],
   "source": [
    "# Box Plot of\n",
    "mean= np.mean(results)\n",
    "std= np.std(results)\n",
    "print(f'Semantic results {mean} +/- {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7],\n",
       "       [9]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(np.array(results)==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 9]),)\n",
      "[0 1 2 3 4 5 6 7 9]\n",
      "          x1        x2        x3        x4        x5        x6        x7\n",
      "0   0.950388  0.314214  0.622695  0.682605  0.565240  0.346935  0.586647\n",
      "3  -0.079119  0.231044  0.381580  0.778734  0.607336  0.471016  0.545712\n",
      "6  -0.010000  0.354386  0.511847  0.793556  0.684749  0.302421  0.251932\n",
      "10  0.940655  0.363552  0.447117  0.746392  0.419121  0.608843  0.469797\n",
      "11 -0.174881  0.320011  0.344394  0.414581  0.512015  0.513694  0.464991\n",
      "12 -0.039291  0.329770  0.501268  0.717560  0.594921  0.347165  0.425024\n",
      "13 -0.010000  0.292091  0.373074  0.772456  0.436068  0.593355  0.585325\n",
      "15 -0.068934  0.328562  0.119524  0.792526  0.449305  0.554376  0.589945\n",
      "19 -0.129184  0.312789  0.480803  0.613174  0.543772  0.386008  0.509848\n",
      "[0.5047729  0.5020996  0.5683795  0.5091228  0.5511703  0.5598251\n",
      " 0.5430247  0.5551793  0.54796386]\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "# Data Distribution\n",
    "id_comp= np.where(np.array(results)==1)\n",
    "id_not_comp=np.where(np.array(results)==0)\n",
    "print(id_not_comp)\n",
    "if len(id_comp[0])==0:\n",
    "    cfs_complient=[]\n",
    "    cfs_complient_predict=[]\n",
    "    \n",
    "else:\n",
    "    cfs_complient=cfs.iloc[id_comp[0]]\n",
    "    cfs_complient_predict=np.max(ml_model.predict(np.array(cfs_complient.values).reshape(-1,cfs_complient.values.shape[-1])),axis=1)\n",
    "cfs_not_complient=cfs.iloc[id_not_comp[0]]\n",
    "\n",
    "#TODO\n",
    "\n",
    "cfs_not_complient_predict=np.max(ml_model.predict(np.array(cfs_not_complient).reshape(-1,7)),axis=1)\n",
    "\n",
    "#df_complient = pd.DataFrame(np.array([cfs_complient_predict,cfs_not_complient_predict]), columns=['complient','not complient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5047729  0.5020996  0.5683795  0.5091228  0.5511703  0.5598251\n",
      " 0.5430247  0.5551793  0.54796386]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#BoxPlot\n",
    "# Drob na \n",
    "import  numpy\n",
    "from math import nan, isnan\n",
    "cfs_complient_predict = [x for x in cfs_complient_predict if isnan(x) == False]\n",
    "cfs_not_complient_predict = [x for x in cfs_not_complient_predict if isnan(x) == False]\n",
    "cfs_complient_predict=np.array(cfs_complient_predict).reshape(-1)\n",
    "cfs_not_complient_predict=np.array(cfs_not_complient_predict).reshape(-1)\n",
    "\n",
    "print(cfs_not_complient_predict)\n",
    "data = [cfs_complient_predict,cfs_not_complient_predict]\n",
    "\n",
    "fig7, ax7 = plt.subplots()\n",
    "ax7.set_title('Complient vs Not Complient')\n",
    "ax7.boxplot(data)\n",
    "\n",
    "#plt.ylim((0.99,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin Plot \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('CARLA-koH0yuP4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f55703f6f29bf5b3ae6360c8e9dbcc23e2b3226583ad9e6051e8921906faedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
