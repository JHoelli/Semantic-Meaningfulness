{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jacqueline/.local/share/virtualenvs/CARLA-koH0yuP4/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n"
     ]
    }
   ],
   "source": [
    "from carla import Benchmark\n",
    "from IPython.display import display\n",
    "import carla.evaluation.catalog as evaluation_catalog\n",
    "from carla.data.catalog import OnlineCatalog\n",
    "from carla.models.catalog import MLModelCatalog\n",
    "from carla.models.negative_instances import predict_negative_instances\n",
    "import carla.recourse_methods.catalog as recourse_catalog\n",
    "import shap \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from carla.data.causal_model import CausalModel\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from carla.data.catalog import CsvCatalog\n",
    "import numpy as np \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the causal model\n",
    "scm = CausalModel(\"credit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"232pt\" height=\"260pt\"\n viewBox=\"0.00 0.00 232.21 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-256 228.2076,-256 228.2076,4 -4,4\"/>\n<!-- x3 -->\n<g id=\"node1\" class=\"node\">\n<title>x3</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"150.2258\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"150.2258\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x3</text>\n</g>\n<!-- x6 -->\n<g id=\"node2\" class=\"node\">\n<title>x6</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"150.2258\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"150.2258\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x6</text>\n</g>\n<!-- x3&#45;&gt;x6 -->\n<g id=\"edge9\" class=\"edge\">\n<title>x3&#45;&gt;x6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M150.2258,-143.8314C150.2258,-136.131 150.2258,-126.9743 150.2258,-118.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"153.7259,-118.4132 150.2258,-108.4133 146.7259,-118.4133 153.7259,-118.4132\"/>\n</g>\n<!-- x7 -->\n<g id=\"node4\" class=\"node\">\n<title>x7</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"150.2258\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"150.2258\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x7</text>\n</g>\n<!-- x6&#45;&gt;x7 -->\n<g id=\"edge11\" class=\"edge\">\n<title>x6&#45;&gt;x7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M150.2258,-71.8314C150.2258,-64.131 150.2258,-54.9743 150.2258,-46.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"153.7259,-46.4132 150.2258,-36.4133 146.7259,-46.4133 153.7259,-46.4132\"/>\n</g>\n<!-- x2 -->\n<g id=\"node3\" class=\"node\">\n<title>x2</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"77.2258\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"77.2258\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x2</text>\n</g>\n<!-- x2&#45;&gt;x3 -->\n<g id=\"edge5\" class=\"edge\">\n<title>x2&#45;&gt;x3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M92.3514,-219.0816C102.5603,-209.0125 116.2136,-195.5463 127.695,-184.2221\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"130.2064,-186.6611 134.8683,-177.147 125.2909,-181.6773 130.2064,-186.6611\"/>\n</g>\n<!-- x2&#45;&gt;x6 -->\n<g id=\"edge8\" class=\"edge\">\n<title>x2&#45;&gt;x6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M83.3278,-216.2804C89.9675,-197.7834 101.3692,-168.1603 114.2258,-144 119.4659,-134.1528 126.0369,-123.846 132.1259,-114.9077\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"135.1432,-116.6995 137.9869,-106.4934 129.3993,-112.6985 135.1432,-116.6995\"/>\n</g>\n<!-- x4 -->\n<g id=\"node5\" class=\"node\">\n<title>x4</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"40.2258\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"40.2258\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x4</text>\n</g>\n<!-- x2&#45;&gt;x4 -->\n<g id=\"edge6\" class=\"edge\">\n<title>x2&#45;&gt;x4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M68.4573,-216.937C64.0978,-208.4537 58.7305,-198.0092 53.8505,-188.513\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"56.8721,-186.7352 49.1883,-179.4407 50.6461,-189.9348 56.8721,-186.7352\"/>\n</g>\n<!-- x5 -->\n<g id=\"node6\" class=\"node\">\n<title>x5</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"40.2258\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"40.2258\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x5</text>\n</g>\n<!-- x2&#45;&gt;x5 -->\n<g id=\"edge7\" class=\"edge\">\n<title>x2&#45;&gt;x5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.4666,-224.2216C37.1793,-215.4263 14.6577,-200.6926 4.2258,-180 -6.7613,-158.2061 6.2549,-132.22 19.6037,-113.7866\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"22.5467,-115.7015 25.8769,-105.6436 17.0014,-111.4295 22.5467,-115.7015\"/>\n</g>\n<!-- x4&#45;&gt;x5 -->\n<g id=\"edge10\" class=\"edge\">\n<title>x4&#45;&gt;x5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M40.2258,-143.8314C40.2258,-136.131 40.2258,-126.9743 40.2258,-118.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"43.7259,-118.4132 40.2258,-108.4133 36.7259,-118.4133 43.7259,-118.4132\"/>\n</g>\n<!-- x1 -->\n<g id=\"node7\" class=\"node\">\n<title>x1</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"168.2258\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"168.2258\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x1</text>\n</g>\n<!-- x1&#45;&gt;x3 -->\n<g id=\"edge1\" class=\"edge\">\n<title>x1&#45;&gt;x3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M163.7763,-216.2022C161.7859,-208.2406 159.3925,-198.6671 157.1747,-189.7957\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"160.5073,-188.6951 154.6864,-179.8425 153.7163,-190.3929 160.5073,-188.6951\"/>\n</g>\n<!-- x1&#45;&gt;x6 -->\n<g id=\"edge4\" class=\"edge\">\n<title>x1&#45;&gt;x6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M186.553,-220.6978C198.3449,-210.9363 212.6513,-196.5364 219.2258,-180 225.137,-165.132 226.2338,-158.3836 219.2258,-144 211.2253,-127.5796 195.5493,-114.6826 181.1584,-105.6165\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"182.8345,-102.5415 172.4443,-100.4693 179.2744,-108.5686 182.8345,-102.5415\"/>\n</g>\n<!-- x1&#45;&gt;x4 -->\n<g id=\"edge2\" class=\"edge\">\n<title>x1&#45;&gt;x4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M147.3755,-222.2717C126.3624,-210.4519 93.7331,-192.0979 70.0001,-178.7481\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"71.4988,-175.5754 61.0671,-173.7233 68.067,-181.6764 71.4988,-175.5754\"/>\n</g>\n<!-- x1&#45;&gt;x5 -->\n<g id=\"edge3\" class=\"edge\">\n<title>x1&#45;&gt;x5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M178.5672,-217.1947C188.9909,-197.863 201.5233,-165.9684 186.2258,-144 173.2895,-125.4226 114.7594,-108.034 75.8497,-98.2341\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"76.482,-94.7853 65.9352,-95.7933 74.8086,-101.5824 76.482,-94.7853\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7faaad527690>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualize the model\n",
    "scm.cgm.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x6</th>\n",
       "      <th>x5</th>\n",
       "      <th>x7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.397051</td>\n",
       "      <td>-0.040466</td>\n",
       "      <td>0.188113</td>\n",
       "      <td>-2.853309</td>\n",
       "      <td>-0.056990</td>\n",
       "      <td>3.908160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.793393</td>\n",
       "      <td>-0.163504</td>\n",
       "      <td>-0.837680</td>\n",
       "      <td>4.533176</td>\n",
       "      <td>-0.314745</td>\n",
       "      <td>8.131771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.802867</td>\n",
       "      <td>-0.123910</td>\n",
       "      <td>1.518897</td>\n",
       "      <td>1.290734</td>\n",
       "      <td>2.294089</td>\n",
       "      <td>-8.192429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.288477</td>\n",
       "      <td>-0.108031</td>\n",
       "      <td>1.263543</td>\n",
       "      <td>-0.489085</td>\n",
       "      <td>5.488899</td>\n",
       "      <td>4.242939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.303859</td>\n",
       "      <td>-0.015351</td>\n",
       "      <td>1.195834</td>\n",
       "      <td>4.138787</td>\n",
       "      <td>1.757983</td>\n",
       "      <td>-4.666042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.686998</td>\n",
       "      <td>-0.286660</td>\n",
       "      <td>-7.247662</td>\n",
       "      <td>-0.859396</td>\n",
       "      <td>-11.929608</td>\n",
       "      <td>-13.097775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.997002</td>\n",
       "      <td>-0.249561</td>\n",
       "      <td>-0.458157</td>\n",
       "      <td>-2.577439</td>\n",
       "      <td>-13.036919</td>\n",
       "      <td>-7.050404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.513357</td>\n",
       "      <td>-0.059398</td>\n",
       "      <td>-0.084656</td>\n",
       "      <td>2.033270</td>\n",
       "      <td>2.486775</td>\n",
       "      <td>7.529237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.968142</td>\n",
       "      <td>-0.031890</td>\n",
       "      <td>-2.018651</td>\n",
       "      <td>3.758463</td>\n",
       "      <td>-0.043503</td>\n",
       "      <td>2.604515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-14.427292</td>\n",
       "      <td>-0.123966</td>\n",
       "      <td>-4.388918</td>\n",
       "      <td>-1.834551</td>\n",
       "      <td>-3.341162</td>\n",
       "      <td>-9.191310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label   x1         x2        x3        x4        x6         x5         x7\n",
       "0      1.0  0.0   3.397051 -0.040466  0.188113 -2.853309  -0.056990   3.908160\n",
       "1      1.0  0.0  17.793393 -0.163504 -0.837680  4.533176  -0.314745   8.131771\n",
       "2      0.0  0.0  -2.802867 -0.123910  1.518897  1.290734   2.294089  -8.192429\n",
       "3      1.0  1.0  -5.288477 -0.108031  1.263543 -0.489085   5.488899   4.242939\n",
       "4      1.0  0.0  16.303859 -0.015351  1.195834  4.138787   1.757983  -4.666042\n",
       "..     ...  ...        ...       ...       ...       ...        ...        ...\n",
       "995    0.0  0.0 -14.686998 -0.286660 -7.247662 -0.859396 -11.929608 -13.097775\n",
       "996    0.0  0.0 -15.997002 -0.249561 -0.458157 -2.577439 -13.036919  -7.050404\n",
       "997    1.0  1.0  16.513357 -0.059398 -0.084656  2.033270   2.486775   7.529237\n",
       "998    1.0  1.0  24.968142 -0.031890 -2.018651  3.758463  -0.043503   2.604515\n",
       "999    0.0  1.0 -14.427292 -0.123966 -4.388918 -1.834551  -3.341162  -9.191310\n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Generate Data from Causal Graph\n",
    "dataset = scm.generate_dataset(1000)\n",
    "dataset.df.to_csv('credit_synthetic.csv',index=False)\n",
    "display(dataset.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Dataset usable with Wachter\n",
    "import pandas as pd\n",
    "# Load Data \n",
    "dataframe = pd.read_csv('./credit_synthetic.csv')\n",
    "continuous = dataframe.drop(columns=['label']).columns\n",
    "\n",
    "dataset = CsvCatalog(file_path=\"credit_synthetic.csv\",\n",
    "                     continuous=continuous,\n",
    "                     categorical=[],\n",
    "                     immutables=[],\n",
    "                     target='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance on test set 0.48933333333333334, balance on test set 0.512\n",
      "Epoch 0/2\n",
      "----------\n",
      "train Loss: 0.6858 Acc: 0.5853\n",
      "\n",
      "test Loss: 0.6332 Acc: 0.6960\n",
      "\n",
      "Epoch 1/2\n",
      "----------\n",
      "train Loss: 0.5910 Acc: 0.7147\n",
      "\n",
      "test Loss: 0.5296 Acc: 0.7960\n",
      "\n",
      "Epoch 2/2\n",
      "----------\n",
      "train Loss: 0.4761 Acc: 0.8027\n",
      "\n",
      "test Loss: 0.4145 Acc: 0.8480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model \n",
    "\n",
    "training_params = {\"lr\": 0.01, \"epochs\": 3, \"batch_size\": 16, \"hidden_size\": [18, 9, 2]}\n",
    "\n",
    "ml_model = MLModelCatalog(\n",
    "    dataset, model_type=\"ann\", load_online=False, backend=\"pytorch\"\n",
    ")\n",
    "ml_model.train(\n",
    "    learning_rate=training_params[\"lr\"],\n",
    "    epochs=training_params[\"epochs\"],\n",
    "    batch_size=training_params[\"batch_size\"],\n",
    "    hidden_size=training_params[\"hidden_size\"],\n",
    "    force_train=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x6</th>\n",
       "      <th>x5</th>\n",
       "      <th>x7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.426373</td>\n",
       "      <td>0.441288</td>\n",
       "      <td>0.532526</td>\n",
       "      <td>0.267621</td>\n",
       "      <td>0.505929</td>\n",
       "      <td>0.684383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325281</td>\n",
       "      <td>0.331484</td>\n",
       "      <td>0.600641</td>\n",
       "      <td>0.554987</td>\n",
       "      <td>0.568483</td>\n",
       "      <td>0.346572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.284752</td>\n",
       "      <td>0.352379</td>\n",
       "      <td>0.587571</td>\n",
       "      <td>0.431567</td>\n",
       "      <td>0.653485</td>\n",
       "      <td>0.693729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354755</td>\n",
       "      <td>0.345386</td>\n",
       "      <td>0.486375</td>\n",
       "      <td>0.457458</td>\n",
       "      <td>0.421985</td>\n",
       "      <td>0.418249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371151</td>\n",
       "      <td>0.300334</td>\n",
       "      <td>0.649358</td>\n",
       "      <td>0.424706</td>\n",
       "      <td>0.571012</td>\n",
       "      <td>0.504250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450260</td>\n",
       "      <td>0.033095</td>\n",
       "      <td>0.629604</td>\n",
       "      <td>0.360440</td>\n",
       "      <td>0.511894</td>\n",
       "      <td>0.648565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.291022</td>\n",
       "      <td>0.294433</td>\n",
       "      <td>0.545914</td>\n",
       "      <td>0.498596</td>\n",
       "      <td>0.559711</td>\n",
       "      <td>0.699538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.280107</td>\n",
       "      <td>0.435865</td>\n",
       "      <td>0.590811</td>\n",
       "      <td>0.247067</td>\n",
       "      <td>0.641397</td>\n",
       "      <td>0.545997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346507</td>\n",
       "      <td>0.228290</td>\n",
       "      <td>0.518979</td>\n",
       "      <td>0.615482</td>\n",
       "      <td>0.482370</td>\n",
       "      <td>0.572586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.148899</td>\n",
       "      <td>0.280159</td>\n",
       "      <td>0.314225</td>\n",
       "      <td>0.580427</td>\n",
       "      <td>0.314377</td>\n",
       "      <td>0.598107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.137273</td>\n",
       "      <td>0.233589</td>\n",
       "      <td>0.414924</td>\n",
       "      <td>0.344018</td>\n",
       "      <td>0.552454</td>\n",
       "      <td>0.209165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287891</td>\n",
       "      <td>0.599838</td>\n",
       "      <td>0.450839</td>\n",
       "      <td>0.498339</td>\n",
       "      <td>0.528809</td>\n",
       "      <td>0.619873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.267942</td>\n",
       "      <td>0.306279</td>\n",
       "      <td>0.505583</td>\n",
       "      <td>0.128555</td>\n",
       "      <td>0.297258</td>\n",
       "      <td>0.402787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349713</td>\n",
       "      <td>0.366461</td>\n",
       "      <td>0.431386</td>\n",
       "      <td>0.560817</td>\n",
       "      <td>0.367130</td>\n",
       "      <td>0.485965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.131074</td>\n",
       "      <td>0.219516</td>\n",
       "      <td>0.468659</td>\n",
       "      <td>0.371916</td>\n",
       "      <td>0.497487</td>\n",
       "      <td>0.476699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323929</td>\n",
       "      <td>0.286196</td>\n",
       "      <td>0.566452</td>\n",
       "      <td>0.429975</td>\n",
       "      <td>0.665476</td>\n",
       "      <td>0.361173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199907</td>\n",
       "      <td>0.409905</td>\n",
       "      <td>0.592112</td>\n",
       "      <td>0.620149</td>\n",
       "      <td>0.595186</td>\n",
       "      <td>0.565547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464235</td>\n",
       "      <td>0.637039</td>\n",
       "      <td>0.433269</td>\n",
       "      <td>0.402360</td>\n",
       "      <td>0.348648</td>\n",
       "      <td>0.371953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.318784</td>\n",
       "      <td>0.353281</td>\n",
       "      <td>0.705087</td>\n",
       "      <td>0.411424</td>\n",
       "      <td>0.555583</td>\n",
       "      <td>0.152894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.322367</td>\n",
       "      <td>0.262140</td>\n",
       "      <td>0.666843</td>\n",
       "      <td>0.655033</td>\n",
       "      <td>0.574432</td>\n",
       "      <td>0.396706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.243006</td>\n",
       "      <td>0.194144</td>\n",
       "      <td>0.478740</td>\n",
       "      <td>0.554899</td>\n",
       "      <td>0.519475</td>\n",
       "      <td>0.537200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.373439</td>\n",
       "      <td>0.483800</td>\n",
       "      <td>0.515799</td>\n",
       "      <td>0.438135</td>\n",
       "      <td>0.447323</td>\n",
       "      <td>0.472708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339121</td>\n",
       "      <td>0.566976</td>\n",
       "      <td>0.599290</td>\n",
       "      <td>0.453702</td>\n",
       "      <td>0.412074</td>\n",
       "      <td>0.585472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290505</td>\n",
       "      <td>0.596018</td>\n",
       "      <td>0.529617</td>\n",
       "      <td>0.265696</td>\n",
       "      <td>0.528920</td>\n",
       "      <td>0.532413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408165</td>\n",
       "      <td>0.349619</td>\n",
       "      <td>0.525159</td>\n",
       "      <td>0.337707</td>\n",
       "      <td>0.576300</td>\n",
       "      <td>0.558787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label   x1        x2        x3        x4        x6        x5        x7\n",
       "0     1.0  0.0  0.426373  0.441288  0.532526  0.267621  0.505929  0.684383\n",
       "2     0.0  0.0  0.325281  0.331484  0.600641  0.554987  0.568483  0.346572\n",
       "3     1.0  1.0  0.284752  0.352379  0.587571  0.431567  0.653485  0.693729\n",
       "10    0.0  0.0  0.354755  0.345386  0.486375  0.457458  0.421985  0.418249\n",
       "14    0.0  0.0  0.371151  0.300334  0.649358  0.424706  0.571012  0.504250\n",
       "15    1.0  0.0  0.450260  0.033095  0.629604  0.360440  0.511894  0.648565\n",
       "17    1.0  1.0  0.291022  0.294433  0.545914  0.498596  0.559711  0.699538\n",
       "18    1.0  1.0  0.280107  0.435865  0.590811  0.247067  0.641397  0.545997\n",
       "20    0.0  0.0  0.346507  0.228290  0.518979  0.615482  0.482370  0.572586\n",
       "22    0.0  1.0  0.148899  0.280159  0.314225  0.580427  0.314377  0.598107\n",
       "25    0.0  1.0  0.137273  0.233589  0.414924  0.344018  0.552454  0.209165\n",
       "26    0.0  1.0  0.287891  0.599838  0.450839  0.498339  0.528809  0.619873\n",
       "29    0.0  0.0  0.267942  0.306279  0.505583  0.128555  0.297258  0.402787\n",
       "30    0.0  0.0  0.349713  0.366461  0.431386  0.560817  0.367130  0.485965\n",
       "33    0.0  1.0  0.131074  0.219516  0.468659  0.371916  0.497487  0.476699\n",
       "35    0.0  0.0  0.323929  0.286196  0.566452  0.429975  0.665476  0.361173\n",
       "36    0.0  0.0  0.199907  0.409905  0.592112  0.620149  0.595186  0.565547\n",
       "39    1.0  0.0  0.464235  0.637039  0.433269  0.402360  0.348648  0.371953\n",
       "40    1.0  1.0  0.318784  0.353281  0.705087  0.411424  0.555583  0.152894\n",
       "41    0.0  1.0  0.322367  0.262140  0.666843  0.655033  0.574432  0.396706\n",
       "42    0.0  1.0  0.243006  0.194144  0.478740  0.554899  0.519475  0.537200\n",
       "45    0.0  1.0  0.373439  0.483800  0.515799  0.438135  0.447323  0.472708\n",
       "49    1.0  0.0  0.339121  0.566976  0.599290  0.453702  0.412074  0.585472\n",
       "53    1.0  0.0  0.290505  0.596018  0.529617  0.265696  0.528920  0.532413\n",
       "54    0.0  0.0  0.408165  0.349619  0.525159  0.337707  0.576300  0.558787"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from carla.models.negative_instances import predict_negative_instances\n",
    "import carla.recourse_methods.catalog as recourse_catalog\n",
    "\n",
    "# Find Factuals\n",
    "factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "test_factual = factuals.iloc[:25]\n",
    "\n",
    "display(test_factual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n",
      "[INFO] Counterfactual Explanation Found [wachter.py wachter_recourse]\n"
     ]
    }
   ],
   "source": [
    "#Find Counterfactuals\n",
    "hyperparams = {\"loss_type\": \"BCE\"}\n",
    "\n",
    "recourse_method = recourse_catalog.Wachter(ml_model, hyperparams)\n",
    "cfs = recourse_method.get_counterfactuals(test_factual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_from_causal(scm,values,cf_label, mapping_dict):\n",
    "    '''\n",
    "    Infers the prediction from the causal model\n",
    "    Attributes: \n",
    "        scm: structural causal model \n",
    "        values: The counterfactual \n",
    "        cf_label: The counterfactual label \n",
    "        mapping_dict: variable name mapping betwenn CF and causal model\n",
    "    Returns Label\n",
    "    '''\n",
    "    values['target']=cf_label\n",
    "    #print(values)\n",
    "    def _get_noise_string(node):\n",
    "        def _get_node_id(node):\n",
    "            return node[1:]\n",
    "        if not node[0] == \"x\":\n",
    "            raise ValueError\n",
    "        return \"u\" + _get_node_id(node)\n",
    "    exogenous_variables = np.concatenate(\n",
    "        [\n",
    "            #np.array(scm.noise_distributions[node].sample(1)).reshape(-1, 1)\n",
    "            np.array(values[mapping_dict[node]]).reshape(-1, 1)\n",
    "            for node in scm.get_topological_ordering(\"exogenous\")\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    exogenous_variables = pd.DataFrame(\n",
    "        exogenous_variables, columns=scm.get_topological_ordering(\"exogenous\")\n",
    "    )\n",
    "\n",
    "    endogenous_variables =exogenous_variables.copy() # np.array(values[mapping_dict[node]]).reshape(-1, 1)\n",
    "    endogenous_variables = endogenous_variables.rename(\n",
    "        columns=dict(\n",
    "            zip(\n",
    "                scm.get_topological_ordering(\"exogenous\"),\n",
    "                scm.get_topological_ordering(\"endogenous\"),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    # used later to make sure parents are populated when computing children\n",
    "    endogenous_variables.loc[:] = np.nan\n",
    "    for node in scm.get_topological_ordering(\"endogenous\"):\n",
    "        #print(node)\n",
    "        parents = scm.get_parents(node)\n",
    "        if endogenous_variables.loc[:, list(parents)].isnull().values.any():\n",
    "            raise ValueError(\n",
    "                \"parents in endogenous_variables should already be occupied\"\n",
    "            )\n",
    "        #print(_get_noise_string(node))\n",
    "        endogenous_variables[node] = scm.structural_equations_np[node](\n",
    "            exogenous_variables[_get_noise_string(node)],\n",
    "            *[endogenous_variables[p] for p in parents],\n",
    "\n",
    "\n",
    "        )\n",
    "    # fix a hyperplane\n",
    "    w = np.ones((endogenous_variables.shape[1], 1))\n",
    "    # get the average scale of (w^T)*X, this depends on the scale of the data\n",
    "    scale = 2.5 / np.mean(np.abs(np.dot(endogenous_variables, w)))\n",
    "    predictions = 1 / (1 + np.exp(-scale * np.dot(endogenous_variables, w)))\n",
    "\n",
    "    uniform_rv = np.random.rand(endogenous_variables.shape[0], 1)\n",
    "    labels = int(uniform_rv < predictions)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict={ \n",
    "    # Gender\n",
    "      'u1': 'x1',\n",
    "      # Age\n",
    "      'u2': 'x2',\n",
    "      # Education\n",
    "      'u3': 'x3',\n",
    "      # Loan amount\n",
    "      'u4':'x4',\n",
    "      # Loan duration\n",
    "      'u5': 'x5',\n",
    "      # Income\n",
    "      'u6': 'x6',\n",
    "      # Savings\n",
    "      'u7':'x7',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cflabel [[0.516347]]\n",
      "cflabel [[0.52036315]]\n",
      "cflabel [[0.52445024]]\n",
      "cflabel [[0.50316715]]\n",
      "cflabel [[0.5058209]]\n",
      "cflabel [[0.5229139]]\n",
      "cflabel [[0.5040144]]\n",
      "cflabel [[0.51248294]]\n",
      "cflabel [[0.50065756]]\n",
      "cflabel [[0.51827776]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cmath import nan\n",
    "from telnetlib import SE\n",
    "from carla.data import causal_model\n",
    "from carla.evaluation import remove_nans\n",
    "from carla.evaluation.api import Evaluation\n",
    "class Sematic(Evaluation):\n",
    "    \"\"\"\n",
    "    Semnatic Evaluation Metric.\n",
    "    Attributes: \n",
    "        ml_model: Machine Learning Model\n",
    "        causal_graph: ground truth causal graph\n",
    "        mapping_dict: name mapping\n",
    "    Returns: Consistency\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ml_model, causal_graph,mapping_dict):\n",
    "        self.ml_model= ml_model\n",
    "        self.causal_graph=causal_graph\n",
    "        self.mapping_dict=mapping_dict\n",
    "    def get_evaluation(self,factuals: np.ndarray, counterfactuals: np.ndarray):\n",
    "        # generate data \n",
    "        cf_label=self.ml_model.predict(np.array(counterfactuals.values).reshape(-1,counterfactuals.values.shape[-1]))\n",
    "        print('cflabel', cf_label)\n",
    "        if cf_label[0][0] > 0.5: \n",
    "            cf_label=1\n",
    "        else:\n",
    "            cf_label=0\n",
    "        causal_label=get_pred_from_causal(self.causal_graph,counterfactuals,cf_label, self.mapping_dict)\n",
    "        if cf_label ==causal_label:\n",
    "            return pd.DataFrame([[1]], columns=[\"semantic\"])\n",
    "        else: \n",
    "            return pd.DataFrame([[0]], columns=[\"semantic\"])\n",
    "\n",
    "# Run metric for the generated counterfactuals \n",
    "results=[]\n",
    "i=0\n",
    "\n",
    "for a in test_factual.index:\n",
    "\n",
    "    if str(cfs.iloc[i]['x1'])=='nan':\n",
    "        pass\n",
    "    else:\n",
    "        sem= Sematic(ml_model,scm,mapping_dict)\n",
    "        try:\n",
    "            res=sem.get_evaluation(test_factual.iloc[a],cfs.iloc[i])['semantic'][0]\n",
    "            results.append( res)\n",
    "        except: \n",
    "            pass\n",
    "    i=i+1\n",
    "\n",
    "'''\n",
    "This is the CARLA Way --> not used as the CF were created previously and therefore do not need to be recreated\n",
    "'''\n",
    "#benchmark = Benchmark(ml_model, recourse_method, factuals[:20])\n",
    "\n",
    "# now you can decide if you want to run all measurements\n",
    "# or just specific ones.\n",
    "#evaluation_measures = [\n",
    "#    Sematic(ml_model,scm,mapping_dict)\n",
    "#]\n",
    "\n",
    "#results = benchmark.run_benchmark(evaluation_measures)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic results 0.2 +/- 0.4000000000000001\n"
     ]
    }
   ],
   "source": [
    "# Averaging of the reults\n",
    "mean= np.mean(results)\n",
    "std= np.std(results)\n",
    "print(f'Semantic results {mean} +/- {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 2, 3, 4, 5, 6, 7, 8]),)\n"
     ]
    }
   ],
   "source": [
    "# Building Probability Distribution of the output divided into complient/ not complient\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "# Data Distribution\n",
    "id_comp= np.where(np.array(results)==1)\n",
    "id_not_comp=np.where(np.array(results)==0)\n",
    "print(id_not_comp)\n",
    "if len(id_comp[0])==0:\n",
    "    cfs_complient=[]\n",
    "    cfs_complient_predict=[]\n",
    "    \n",
    "else:\n",
    "    cfs_complient=cfs.iloc[id_comp[0]]\n",
    "    cfs_complient_predict=np.max(ml_model.predict(np.array(cfs_complient.values).reshape(-1,cfs_complient.values.shape[-1])),axis=1)\n",
    "cfs_not_complient=cfs.iloc[id_not_comp[0]]\n",
    "\n",
    "\n",
    "cfs_not_complient_predict=np.max(ml_model.predict(np.array(cfs_not_complient).reshape(-1,7)),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52036315 0.52445024 0.50316715 0.5058209  0.5229139  0.5040144\n",
      " 0.51248294 0.50065756]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#BoxPlot\n",
    "import  numpy\n",
    "from math import nan, isnan\n",
    "cfs_complient_predict = [x for x in cfs_complient_predict if isnan(x) == False]\n",
    "cfs_not_complient_predict = [x for x in cfs_not_complient_predict if isnan(x) == False]\n",
    "cfs_complient_predict=np.array(cfs_complient_predict).reshape(-1)\n",
    "cfs_not_complient_predict=np.array(cfs_not_complient_predict).reshape(-1)\n",
    "\n",
    "print(cfs_not_complient_predict)\n",
    "data = [cfs_complient_predict,cfs_not_complient_predict]\n",
    "\n",
    "fig7, ax7 = plt.subplots()\n",
    "ax7.set_title('Complient vs Not Complient')\n",
    "ax7.boxplot(data)\n",
    "\n",
    "#plt.ylim((0.99,1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('CARLA-koH0yuP4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f55703f6f29bf5b3ae6360c8e9dbcc23e2b3226583ad9e6051e8921906faedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
